{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "WzajGhK3ZxPT",
    "tags": [
     "parameters"
    ]
   },
   "source": [
    "# **Fundamentals of Data Science - Winter Semester 2024**\n",
    "\n",
    "\n",
    "##### Matteo Migliarini (TA), Matteo Rampolla (TA) and Prof. Indro Spinelli\n",
    "<migliarini.1886186@studenti.uniroma1.it>, <rampolla.1762214@studenti.uniroma1.it>, <spinelli@di.uniroma1.it>\n",
    "\n",
    "---\n",
    "\n",
    "## **#1 Homework: Image Filtering and Object Identification** v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eV6CqjqgdLUt"
   },
   "source": [
    "This first homework covers the main topics discussed in class.\n",
    "Initially, you will be dealing with the original **Image Filtering** methods (*Question 1*), then you will have to work with **Edge Detection** algorithms (*Question 2*), and lastly, you are going to operate first-hand on **Object Identification** techniques (*Question 3*).\n",
    "Additionally, the homework will contain written questions and reports where you will be asked to write down your answer in Markdown language.\n",
    "The maximum possible grade is 30, but notice that you have 5 extra bonus points scattered across the homework to further boost your grade.\n",
    "\n",
    "*Note: your task is to fill in the missing code where you see `\"YOUR CODE HERE\"` and the text part `\"WRITE YOU ANSWER HERE\"` part corresponding to each subproblem and produce brief reports on the results whenever necessary.*\n",
    "\n",
    "As part of the homework, provide the answer to questions in this notebook report-like manner. After you have implemented all the missing code in the required sections, you will be able to run all the code without any errors. We kindly ask you to double-check this since **all** the delivered homework will be executed.\n",
    "\n",
    "The completed exercise should be handed in as a single notebook file. Use Markdown to provide equations. Use the code sections to provide your scripts and the corresponding plots.\n",
    "\n",
    "-------------------------------------\n",
    "\n",
    "**Submit it** by sending an email to:\n",
    "\n",
    " **<migliarini.1886186@studenti.uniroma1.it>, <rampolla.1762214@studenti.uniroma1.it> and <spinelli@di.uniroma1.it> by Sunday 27th October 23:59**.\n",
    "\n",
    "-------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i1rpge3piKN5"
   },
   "source": [
    "**Outline and Scores for #1 Homework:**\n",
    "\n",
    "\n",
    "* **Question 1: Image Filtering** *(7 points)*\n",
    "  * **Question 1.0: Warm Up** *(1 point)*\n",
    "  * **Question 1.1: 1D Filters** *(3 points)*\n",
    "  * **Question 1.2: 2D Filters** *(3 points)*\n",
    "\n",
    "* **Question 2: Multi-Scale Image Representations** *(12 points)*\n",
    "  * **Question 2.1: Prewitt Operator** *(2 point)*\n",
    "  * **Question 2.2: Canny Edge Detector and Template Matching** *(4 points)*\n",
    "  * **Question 2.3: Harris Corner Detector** *(2 points)*\n",
    "  * **Question 2.4: Gaussian Pyramid and Aliasing** *(2 points)*\n",
    "  * **Question 2.5: Multi-Scale Template Matching** *(2 points)*\n",
    "\n",
    "* **Question 3: Object Identification** *(10 points)*\n",
    "  * **Question 3.1: 3D Joint Color Histogram** *(2 points)*\n",
    "  * **Question 3.2: Types of Histograms** *(2 points)*\n",
    "  * **Question 3.3: Histogram Metrics** *(2 points)*\n",
    "  * **Question 3.4: Image Retrieval** *(2 points)*\n",
    "  * **Report** *(2 points)*\n",
    "\n",
    "* **Question 4: Performance Evaluation** *(6 points)*\n",
    "  * **Question 4.1: Performance Evaluation** *(2 point)*\n",
    "  * **Question 4.2: Closest Neighbours** *(2 points)*\n",
    "  * **Question 4.3: Retrieval Metrics** *(1 points)*\n",
    "  * **Question 4.4: Analysis and Report** *(1 point)*\n",
    "\n",
    "\n",
    "**TOTAL POINTS ARE 35, MAX GRADE IS 30**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x2K7arzbdXst"
   },
   "source": [
    "## **Question 1: Image Filtering *(8 Points)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:21:48.040562Z",
     "start_time": "2024-10-24T12:21:46.412335Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Set to True the first time you run this file to install the required packages\n",
    "install_packages = True\n",
    "if install_packages:\n",
    "    %pip install pandas pillow numpy scipy matplotlib opencv-python scikit-image scikit-learn gdown\n",
    "import os\n",
    "if not all(os.path.exists(folder) for folder in ['assets', 'model', 'query', 'images']):\n",
    "    !gdown 1K0V9KkIBELbQbCEdntE_N-eOhP8rAOrA \n",
    "    !unzip -o hw1_data.zip\n",
    "    !rm hw1_data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:21:49.394353Z",
     "start_time": "2024-10-24T12:21:48.042357Z"
    }
   },
   "outputs": [],
   "source": [
    "## import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from scipy.signal import convolve2d\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from scipy.ndimage import convolve1d\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.transform import resize\n",
    "from typing import List, Tuple, Optional, Dict, Union\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:21:49.399500Z",
     "start_time": "2024-10-24T12:21:49.395148Z"
    }
   },
   "outputs": [],
   "source": [
    "def rgb2gray(rgb: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Converts RGB images to grayscale.\n",
    "\n",
    "    Args:\n",
    "        rgb (np.ndarray): RGB image.\n",
    "\n",
    "    Returns:\n",
    "        gray (np.ndarray): Grayscale image.\n",
    "    \"\"\"\n",
    "    r, g, b = rgb[:, :, 0], rgb[:, :, 1], rgb[:, :, 2]\n",
    "    gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "    return gray\n",
    "\n",
    "def plot_pictures(\n",
    "    imgs: List[np.ndarray],\n",
    "    xlabels: List[str],\n",
    "    nrows: int,\n",
    "    ncols: int,\n",
    "    show: bool = True,\n",
    "    cmap: Union[str, List[str]] = \"gray\",\n",
    "    vmin: Optional[float] = None,\n",
    "    vmax: Optional[float] = None,\n",
    "    same_scale: bool = False,\n",
    ") -> List[plt.Axes]:\n",
    "    \"\"\"\n",
    "    Plots images in a grid.\n",
    "\n",
    "    Args:\n",
    "        imgs (list[np.ndarray]): List of images.\n",
    "        xlabels (list[str]): List of xlabels.\n",
    "        nrows (int): Number of rows.\n",
    "        ncols (int): Number of columns.\n",
    "        show (bool): Whether to show the plot.\n",
    "        cmap (Union[str, List[str]]): Color map.\n",
    "        vmin (float): Minimum value.\n",
    "        vmax (float): Maximum value.\n",
    "        same_scale (bool): Whether to use the same scale for all images.\n",
    "\n",
    "    Returns:\n",
    "        axs (list[matplotlib.axes._subplots.AxesSubplot]): List of axes.\n",
    "    \"\"\"\n",
    "    fig, axs = plt.subplots(nrows, ncols,\n",
    "                            width_ratios=[img.shape[1] / img.shape[0] for img in imgs],\n",
    "                            sharey=same_scale,\n",
    "                            figsize=(ncols * 4, nrows * 4))\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    for i, (img, ax) in enumerate(zip(imgs, axs)):\n",
    "        if isinstance(cmap, list):\n",
    "            current_cmap = cmap[i]\n",
    "        else:\n",
    "            current_cmap = cmap\n",
    "        im = ax.imshow(img, cmap=current_cmap, vmin=vmin, vmax=vmax)\n",
    "\n",
    "\n",
    "        ax.set_title(xlabels[i])\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        return axs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### **1.0: Warm Up *(1 points)***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### **Convolution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The convolution is defined as $f[m,n]=I \\ast g= \\sum_{k,l} I[m-k,n-l]g[k,l]$ and is a linear operator, thus the following properties hold:\n",
    "* *Homogeneity*: $T[aX]=aT[X]$\n",
    "* *Additivity* : $T[X_1+X_2]=T[X_1]+T[X_2]$\n",
    "* *Superposition*: $T[aX_1+bX_2]=aT[X_1]+bT[X_2]$\n",
    "\n",
    "Prove mathematically the additivity of convolution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "-------------------------------------------------------\n",
    "\n",
    "**WRITE YOU ANSWER HERE**\n",
    "\n",
    "We want to prove the following property of f: \\\n",
    "$f[[m,n]+[m^{\\prime},n^{\\prime}]]=f\\left\\lbrack m+m^{\\prime},n+n^{\\prime}\\right\\rbrack=f\\left\\lbrack m,n\\right\\rbrack+f\\left\\lbrack m^{\\prime},n^{\\prime}\\right\\rbrack$\n",
    "\n",
    "Initially, we replace f with it's definition: \\\n",
    "$\\sum_{k,l}{I[(m+m')-k,(n+n')-l]g[k,l]}=\\sum_{k,l}{I[m-k,n-l]g[k,l]}+\\sum_{k,l}{I[m'-k,n'-l]g[k,l]}$\n",
    "\n",
    "We apply the associative property of summations on the right part of the equation: \\\n",
    "$\\sum_{k,l}{I[(m+m')-k,(n+n')-l]g[k,l]}=\\sum_{k,l}{I[m-k,n-l]g[k,l] + I[m'-k,n'-l]g[k,l]}$\n",
    "\n",
    "Then we group by $g[k,l]$ and we get the following equation: \\\n",
    "$\\sum_{k,l}{I[(m+m')-k,(n+n')-l]g[k,l]}=\\sum_{k,l}{(I[m-k,n-l] + I[m'-k,n'-l])g[k,l]}$\n",
    "\n",
    "Finally, we can sum the values \\\n",
    "$\\sum_{k,l}{I[(m+m')-k,(n+n')-l]g[k,l]}=\\sum_{k,l}{I[(m+m')-k,(n+n')-l]g[k,l]}$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "-------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Exercise on convolutions**\n",
    "\n",
    "Usually, to be consistent with the definition, we use zero padding: this practice consists of adding a border of zero-valued pixels all around the edges of the input image.\n",
    "In our case, we will have\n",
    "\n",
    "\\begin{equation}\n",
    "f[m,n] =\n",
    "\\begin{pmatrix}\n",
    "0 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 4 & 5 & 7 & 0 \\\\\n",
    "0 & 7 & 3 & 1 & 0 \\\\\n",
    "0 & 9 & 2 & 2 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 0 \\\\\n",
    "\\end{pmatrix}\n",
    "*\\begin{pmatrix}\n",
    "-1 & 0 & 1 \\\\\n",
    "-1 & 0 & 1 \\\\\n",
    "-1 & 0 & 1 \\\\\n",
    "\\end{pmatrix}\n",
    "=\\begin{pmatrix}\n",
    "... & ... & ... \\\\\n",
    "... & -10 & ... \\\\\n",
    "... & ... & ... \\\\\n",
    "\\end{pmatrix}.\n",
    "\\end{equation}\n",
    "\n",
    "Now, given the images $I_1 \\in \\mathbb{N}^{5 \\times 5}$, $I_2 \\in \\mathbb{N}^{5 \\times 5}$, and the kernel $g \\in \\mathbb{N}^{2 \\times 2}$, apply the additivity property for one convolution operation: you should expect that $T[I_1 + I_2]$ and $T[I_1]$ + $T[I_2]$ get the same result.\n",
    "Displaying explicitly the operations you performed, feel free to choose the coordinates to apply the convolution on as you like them.\n",
    "\n",
    "\\begin{equation}\n",
    "    I_1 =\n",
    "    \\begin{pmatrix}\n",
    "        0 & 0 & 0 & 0 & 0 \\\\\n",
    "        0 & 3 & 3 & 5 & 0 \\\\\n",
    "        0 & 2 & 7 & 0 & 0 \\\\\n",
    "        0 & 0 & 2 & 3 & 0 \\\\\n",
    "        0 & 0 & 0 & 0 & 0 \\\\\n",
    "    \\end{pmatrix}, \\quad\n",
    "    I_2 =\n",
    "    \\begin{pmatrix}\n",
    "        0 & 0 & 0 & 0 & 0 \\\\\n",
    "        0 & 3 & 5 & 3 & 0 \\\\\n",
    "        0 & 1 & 0 & 5 & 0 \\\\\n",
    "        0 & 2 & 6 & 8 & 0 \\\\\n",
    "        0 & 0 & 0 & 0 & 0 \\\\\n",
    "    \\end{pmatrix}, \\quad\n",
    "    g =\n",
    "    \\begin{pmatrix}\n",
    "        -1 & 1 \\\\\n",
    "        -1 & 1 \\\\\n",
    "    \\end{pmatrix}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "-------------------------------------------------------\n",
    "\n",
    "**WRITE YOU ANSWER HERE**\n",
    "\n",
    "Write it in Markdown, you are encouraged to take a look at the cells in this notebook.\n",
    "You can find a cheat sheet [here](https://www.markdownguide.org/basic-syntax)\n",
    "\n",
    "\n",
    "Calculating the sum of the two matrices $I_1$ and $I_2$ and applying the convolution operation to the sum, we get the following result:\n",
    "\n",
    "\\begin{equation}\n",
    "    I_1 + I_2 = \\begin{pmatrix}\n",
    "        0 & 0 & 0 & 0 & 0 \\\\\n",
    "        0 & 3 & 3 & 5 & 0 \\\\\n",
    "        0 & 2 & 7 & 0 & 0 \\\\\n",
    "        0 & 0 & 2 & 3 & 0 \\\\\n",
    "        0 & 0 & 0 & 0 & 0 \\\\\n",
    "    \\end{pmatrix} +\n",
    "    \\begin{pmatrix}\n",
    "        0 & 0 & 0 & 0 & 0 \\\\\n",
    "        0 & 3 & 5 & 3 & 0 \\\\\n",
    "        0 & 1 & 0 & 5 & 0 \\\\\n",
    "        0 & 2 & 6 & 8 & 0 \\\\\n",
    "        0 & 0 & 0 & 0 & 0 \\\\\n",
    "    \\end{pmatrix} =\n",
    "    \\begin{pmatrix}\n",
    "        0 & 0 & 0 & 0 & 0 \\\\\n",
    "        0 & 6 & 8 & 8 & 0 \\\\\n",
    "        0 & 3 & 7 & 5 & 0 \\\\\n",
    "        0 & 2 & 8 & 11 & 0 \\\\\n",
    "        0 & 0 & 0 & 0 & 0 \\\\\n",
    "    \\end{pmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Apply the convolution operation to the sum of the two matrices $I_1 + I_2$, let us now see the result line by line by starting the filter from position (0,0) and moving it to the right and then down:\n",
    "> I row: <br>\n",
    "> $(-1*0) + (1*0) + (-1*0) + (1*6) = 6$ <br>\n",
    "> $(-1*0) + (1*0) + (-1*6) + (1*8) = 2$ <br>\n",
    "> $(-1*0) + (1*0) + (-1*8) + (1*8) = 0$ <br>\n",
    "> $(-1*0) + (1*0) + (-1*8) + (1*0) = -8$ <br>\n",
    "\n",
    "> II row: <br>\n",
    "> $(-1*0) + (1*6) + (-1*0) + (1*3) = 9$ <br>\n",
    "> $(-1*6) + (1*8) + (-1*3) + (1*7) = 6$ <br>\n",
    "> $(-1*8) + (1*8) + (-1*7) + (1*5) = -2$ <br>\n",
    "> $(-1*8) + (1*0) + (-1*5) + (1*0) = -13$ <br>\n",
    "\n",
    "> III row: <br>\n",
    "> $(-1*0) + (1*3) + (-1*0) + (1*2) = 5$ <br>\n",
    "> $(-1*3) + (1*7) + (-1*2) + (1*8) = 10$ <br>\n",
    "> $(-1*7) + (1*5) + (-1*8) + (1*11) = 1$ <br>\n",
    "> $(-1*5) + (1*0) + (-1*11) + (1*0) = -16$ <br>\n",
    "\n",
    "> IV row: <br>\n",
    "> $(-1*0) + (1*2) + (-1*0) + (1*0) = 2$ <br>\n",
    "> $(-1*2) + (1*8) + (-1*0) + (1*0) = 6$ <br>\n",
    "> $(-1*8) + (1*11) + (-1*0) + (1*0) = 3$ <br>\n",
    "> $(-1*11) + (1*0) + (-1*0) + (1*0) = -11$ <br>\n",
    "\n",
    "The final result of $T[I_1 + I_2$] is:\n",
    "\\begin{equation}\n",
    "    T[I_1 + I_2] = \\begin{pmatrix}\n",
    "        6 & 2 & 0 & -8 \\\\\n",
    "        9 & 6 & -2 & -13 \\\\\n",
    "        5 & 10 & 1 & -16 \\\\\n",
    "        2 & 6 & 3 & -11 \\\\\n",
    "    \\end{pmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "To verify the correctness of the propiety we are going to apply the same filter to the two matrices and then add them together and verify that they return this same matrix.\n",
    "\n",
    "Apply the convolution operation to the matrix $I_1$, let us now see the result line by line with the same pattern as before:\n",
    "\n",
    "\\begin{equation}\n",
    "    I_1 = \\begin{pmatrix}\n",
    "        0 & 0 & 0 & 0 & 0 \\\\\n",
    "        0 & 3 & 3 & 5 & 0 \\\\\n",
    "        0 & 2 & 7 & 0 & 0 \\\\\n",
    "        0 & 0 & 2 & 3 & 0 \\\\\n",
    "        0 & 0 & 0 & 0 & 0 \\\\\n",
    "    \\end{pmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "> I row: <br>\n",
    "> $(-1*0) + (1*0) + (-1*0) + (1*3) = 3$ <br>\n",
    "> $(-1*0) + (1*0) + (-1*3) + (1*3) = 0$ <br>\n",
    "> $(-1*0) + (1*0) + (-1*3) + (1*5) = 2$ <br>\n",
    "> $(-1*0) + (1*0) + (-1*5) + (1*0) = -5$ <br>\n",
    "\n",
    "> II row: <br>\n",
    "> $(-1*0) + (1*3) + (-1*2) + (1*5) = 5$ <br>\n",
    "> $(-1*3) + (1*3) + (-1*2) + (1*7) = 5$ <br>\n",
    "> $(-1*3) + (1*5) + (-1*7) + (1*0) = -5$ <br>\n",
    "> $(-1*5) + (1*0) + (-1*0) + (1*0) = -5$ <br>\n",
    "\n",
    "> III row: <br>\n",
    "> $(-1*0) + (1*2) + (-1*0) + (1*0) = 2$ <br>\n",
    "> $(-1*2) + (1*7) + (-1*0) + (1*2) = 7$ <br>\n",
    "> $(-1*7) + (1*0) + (-1*2) + (1*3) = -6$ <br>\n",
    "> $(-1*0) + (1*0) + (-1*3) + (1*0) = -3$ <br>\n",
    "\n",
    "> IV row: <br>\n",
    "> $(-1*0) + (1*0) + (-1*0) + (1*0) = 0$ <br>\n",
    "> $(-1*0) + (1*2) + (-1*0) + (1*0) = 2$ <br>\n",
    "> $(-1*2) + (1*3) + (-1*0) + (1*0) = 1$ <br>\n",
    "> $(-1*3) + (1*0) + (-1*0) + (1*0) = -3$ <br>\n",
    "\n",
    "The final result of $T[I_1]$ is:\n",
    "\n",
    "\\begin{equation}\n",
    "    T[I_1] = \\begin{pmatrix}\n",
    "        3 & 0 & 2 & -5 \\\\\n",
    "        5 & 5 & -5 & -5 \\\\\n",
    "        2 & 7 & -6 & -3 \\\\\n",
    "        0 & 2 & 1 & -3 \\\\\n",
    "    \\end{pmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "Apply the convolution operation to the matrix $I_2$, without seeing the calculations, we get the following result:\n",
    "\\begin{equation}\n",
    "    T[I_2] = \\begin{pmatrix}\n",
    "        3 & 2 & -2 & -3 \\\\\n",
    "        4 & 1 & 3 & -8 \\\\\n",
    "        3 & 3 & 7 & -13 \\\\\n",
    "        2 & 4 & 2 & -8 \\\\\n",
    "    \\end{pmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "Now, we can sum the two matrices $T[I_1]$ and $T[I_2]$:\n",
    "\\begin{equation}\n",
    "    T[I_1] + T[I_2] = \\begin{pmatrix}\n",
    "        3 & 0 & 2 & -5 \\\\\n",
    "        5 & 5 & -5 & -5 \\\\\n",
    "        2 & 7 & -6 & -3 \\\\\n",
    "        0 & 2 & 1 & -3 \\\\\n",
    "    \\end{pmatrix} +\n",
    "    \\begin{pmatrix}\n",
    "        3 & 2 & -2 & -3 \\\\\n",
    "        4 & 1 & 3 & -8 \\\\\n",
    "        3 & 3 & 7 & -13 \\\\\n",
    "        2 & 4 & 2 & -8 \\\\\n",
    "    \\end{pmatrix} =\n",
    "    \\begin{pmatrix}\n",
    "        6 & 2 & 0 & -8 \\\\\n",
    "        9 & 6 & -2 & -13 \\\\\n",
    "        5 & 10 & 1 & -16 \\\\\n",
    "        2 & 6 & 3 & -11 \\\\\n",
    "    \\end{pmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "As it turned out, the two matrices corresponded: $T[I_1 + I_2] = T[I_1] + T[I_2]$.\n",
    "\n",
    "\\begin{equation}\n",
    "    T[I_1] + T[I_2] = T[I_1 + I_2] = \\begin{pmatrix}\n",
    "        3 & 0 & 2 & -5 \\\\\n",
    "        5 & 5 & -5 & -5 \\\\\n",
    "        2 & 7 & -6 & -3 \\\\\n",
    "        0 & 2 & 1 & -3 \\\\\n",
    "    \\end{pmatrix} +\n",
    "    \\begin{pmatrix}\n",
    "        3 & 2 & -2 & -3 \\\\\n",
    "        4 & 1 & 3 & -8 \\\\\n",
    "        3 & 3 & 7 & -13 \\\\\n",
    "        2 & 4 & 2 & -8 \\\\\n",
    "    \\end{pmatrix} =\n",
    "    \\begin{pmatrix}\n",
    "        6 & 2 & 0 & -8 \\\\\n",
    "        9 & 6 & -2 & -13 \\\\\n",
    "        5 & 10 & 1 & -16 \\\\\n",
    "        2 & 6 & 3 & -11 \\\\\n",
    "    \\end{pmatrix}\n",
    "\\end{equation}\n",
    "-------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### **1.1: 1D Filters *(3 Points)***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### **1.1.1: 1-D Gaussian Filter**\n",
    "\n",
    "Implement a method which computes the values of a 1-D Gaussian $G_x$ for a given standard deviation $\\sigma$ and filter size $k$.:\n",
    "\\begin{equation}\n",
    "G(x)=\\frac{1}{\\sqrt{2\\pi}\\sigma}\\exp\\left(-\\frac{x^2}{2\\sigma^2}\\right)\n",
    "\\end{equation}\n",
    "\n",
    "The method should return a vector $x$ of values on which the Gaussian filter is defined: integer values on the interval of integers in $\\left[-\\kappa,\\kappa\\right]$ where $2\\kappa =$ `filter_size`.\n",
    "\n",
    "With $\\sigma=3$ and `filter_size=18` you should get the following output:\n",
    "\n",
    "![](./images/1gauss.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:21:49.404222Z",
     "start_time": "2024-10-24T12:21:49.400883Z"
    }
   },
   "outputs": [],
   "source": [
    "def gauss(sigma: int, filter_size: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Computes the Gaussian filter.\n",
    "\n",
    "    Args:\n",
    "        sigma (int): Standard deviation.\n",
    "        filter_size (int): Filter size, be wary that it is the full size of the filter.\n",
    "\n",
    "    Returns:\n",
    "        Gx (np.ndarray): Gaussian filter.\n",
    "        x (np.ndarray): Array of integer values.\n",
    "    \"\"\"\n",
    "    #####################################################\n",
    "    ##                 YOUR CODE HERE                  ##\n",
    "    #####################################################\n",
    "    x = np.arange(-filter_size // 2 , filter_size // 2 + 1)\n",
    "    Gx = np.zeros(x.shape[0])\n",
    "\n",
    "    for i, p in enumerate(np.nditer(x)):\n",
    "        Gx[i] = (1 / (np.sqrt(2 * np.pi) * sigma)) * np.exp(-np.power(p, 2) / (2 * np.power(sigma, 2)))\n",
    "    return Gx, x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "--------------------------------------------\n",
    "\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:21:49.536825Z",
     "start_time": "2024-10-24T12:21:49.404946Z"
    }
   },
   "outputs": [],
   "source": [
    "sigma = 3\n",
    "size = sigma * 6 + 1\n",
    "Gx, x = gauss(sigma, size)\n",
    "plt.figure(1)\n",
    "plt.plot(x, Gx, \".-\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Variation of $\\sigma$ and filter size**\n",
    "\n",
    "Now we generate a signal and apply the Gauss filter with different values of $\\sigma$ and filter size.\n",
    "Write down your considerations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:26:00.594604Z",
     "start_time": "2024-10-24T12:26:00.137409Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generate a noisy signal with increased noise (example data)\n",
    "t = np.linspace(0, 2 * np.pi, 1000)\n",
    "noisy_signal = np.sin(t) + 1.0 * np.random.randn(len(t))  # Increased noise\n",
    "\n",
    "# Define a fixed sigma value\n",
    "sigma = 1\n",
    "\n",
    "# Define a range of filter sizes to test\n",
    "filter_sizes = [18, 30]\n",
    "\n",
    "# Create subplots to compare the denoising results\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for i in range(len(filter_sizes)):\n",
    "    # Get the Gaussian kernel and x values from the custom gauss function\n",
    "    Gx, x = gauss(sigma, filter_sizes[i])\n",
    "\n",
    "    # Convolve the noisy signal with the Gaussian filter\n",
    "    denoised_signal = np.convolve(noisy_signal, Gx, mode=\"same\")\n",
    "\n",
    "    # Plot the noisy and denoised signals for the current filter_size\n",
    "    plt.subplot(len(filter_sizes), 1, i + 1)\n",
    "    plt.plot(t, noisy_signal, label=\"Noisy Signal\")\n",
    "    plt.plot(t, denoised_signal, label=f\"Denoised (Filter Size {filter_sizes[i]})\")\n",
    "    plt.title(f\"Effect of Filter Size on Denoising (Sigma={sigma})\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Define a fixed sigma value\n",
    "sigma = [3, 5]\n",
    "\n",
    "# Define a range of filter sizes to test\n",
    "filter_sizes = 30\n",
    "\n",
    "# Create subplots to compare the denoising results\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for i in range(len(sigma)):\n",
    "    # Get the Gaussian kernel and x values from the custom gauss function\n",
    "    Gx, x = gauss(sigma[i], filter_sizes)\n",
    "    denoised_signal = np.convolve(noisy_signal, Gx, mode=\"same\")\n",
    "\n",
    "    # Plot the noisy and denoised signals for the current filter_size\n",
    "    plt.subplot(len(sigma), 1, i + 1)\n",
    "    plt.plot(t, noisy_signal, label=\"Noisy Signal\")\n",
    "    plt.plot(t, denoised_signal, label=f\"Denoised (Sigma {sigma[i]})\")\n",
    "    plt.title(f\"Effect of Sigma on Denoising (Filter Size={filter_sizes})\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "-------------------------------------------------------\n",
    "\n",
    "**WRITE YOU ANSWER HERE**\n",
    "\n",
    "Effect of filter_size:\n",
    "- A small filter size preserves more of the original signal details but may leave some noise unfiltered. The convolution operation uses fewer neighboring points, resulting in less smoothing.\n",
    "\n",
    "- Increasing the filter_size parameter leads to a bigger kernel. However, the standard deviation of the gaussian curve will remain the same. This means that we are extending the range of points considered in the convolution, although these additional points will have very small weights (due to the Gaussian curve's nature), and the output signal won't change much.\n",
    "\n",
    "Effect of sigma:\n",
    "- A smaller σ (standard deviation) in the Gaussian kernel means the filter focuses more on the center points and less on neighboring points. This leads to less smoothing and keeps finer details, but some noise may remain. Only high-frequency noise will be smoothed.\n",
    "- A larger σ causes the Gaussian kernel to be wider, giving more weight to distant points during convolution. This leads to a much smoother output, removing more noise but potentially erasing some of the signal's finer structures.\n",
    "- Increasing σ results in more aggressive noise reduction, but care must be taken to avoid over-smoothing and losing important signal features.\n",
    "-------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### **1-D Box Filter**\n",
    "\n",
    "Implement a method that computes the values of a 1-D Box $B_x$:\n",
    "\\begin{equation}\n",
    "B= \\left[\\frac{1}{n},\\frac{1}{n},\\dots,\\frac{1}{n}\\right] \\in \\mathbb{R}^n\n",
    "\\end{equation}\n",
    "\n",
    "The method should also return a vector $x$ of values on which the filter is defined: integer values in the interval $\\left[-\\kappa,\\kappa\\right]$ where $2\\kappa =$ `filter_size`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:21:49.960878Z",
     "start_time": "2024-10-24T12:21:49.957695Z"
    }
   },
   "outputs": [],
   "source": [
    "def box(filter_size: int = 3) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Box filter.\n",
    "\n",
    "    Args:\n",
    "        filter_size (int): Filter size.\n",
    "\n",
    "    Returns:\n",
    "        Bx (np.ndarray): Box filter.\n",
    "        x (np.ndarray): x values.\n",
    "    \"\"\"\n",
    "\n",
    "    #####################################################\n",
    "    ##                 YOUR CODE HERE                  ##\n",
    "    #####################################################\n",
    "    x = np.arange(-(filter_size // 2), filter_size // 2 + 1, dtype=int)\n",
    "    Bx = np.repeat(1 / filter_size, filter_size)\n",
    "\n",
    "    return Bx, x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "--------------------------------------------\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:21:50.063184Z",
     "start_time": "2024-10-24T12:21:49.961762Z"
    }
   },
   "outputs": [],
   "source": [
    "## function box\n",
    "size = 3\n",
    "Bx, x = box(size)\n",
    "plt.figure(1)\n",
    "plt.plot(x, Bx, \".-\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### **1.1.2: 1D Laplacian filter**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Derive the 1-D Laplacian $L_x$, then implement a method that computes it for a given standard deviation $\\sigma$ and filter size $2k$. With $\\sigma=3$ and $k=30$ you should expect the following output:\n",
    "\n",
    "![](./images/1laplace.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "-------------------------------------------------------\n",
    "### **WRITE YOU ANSWER HERE**\n",
    "\n",
    "Straight answers not showing the derivation steps will not be accepted.\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{d^2G(x)}{dx^2}=\n",
    "\\end{equation} \n",
    "\n",
    "\\begin{equation}\n",
    "G(x)=\\frac{\\mathrm{e}^{-\\frac{x^{2}}{2{\\sigma}^{2}}}}{\\sqrt{2} \\sqrt{\\pi} \\, {\\sigma}}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\mathrm{d}}{\\mathrm{d}x}\\left[\\frac{\\mathrm{e}^{-\\frac{x^{2}}{2{\\sigma}^{2}}}}{\\sqrt{2} \\sqrt{\\pi} \\, {\\sigma}}\\right]\n",
    "\\end{equation}\n",
    "\n",
    "We can pull out constant factors:\n",
    "\n",
    "\\begin{equation}\n",
    "= \\frac{1}{\\sqrt{2} \\sqrt{\\pi} \\, {\\sigma}} \\cdot \\frac{\\mathrm{d}}{\\mathrm{d}x}\\left[\\mathrm{e}^{-\\frac{x^{2}}{2{\\sigma}^{2}}}\\right]\n",
    "\\end{equation}\n",
    "\n",
    "We apply the exponential function rule: $[e^{u(x)}]'=e^{u(x)}*u'(x)$\n",
    "\n",
    "\\begin{equation}\n",
    "= \\frac{\\mathrm{e}^{-\\frac{x^{2}}{2{\\sigma}^{2}}} \\cdot \\frac{\\mathrm{d}}{\\mathrm{d}x}\\left[-\\frac{x^{2}}{2{\\sigma}^{2}}\\right]}{\\sqrt{2} \\sqrt{\\pi} \\, {\\sigma}}\n",
    "\\end{equation}\n",
    "\n",
    "Again we can pull out constants:\n",
    "\n",
    "\\begin{equation}\n",
    "= \\frac{\\mathrm{e}^{-\\frac{x^{2}}{2{\\sigma}^{2}}} \\left(-\\frac{1}{2{\\sigma}^{2}} \\cdot \\frac{\\mathrm{d}}{\\mathrm{d}x}\\left[x^{2}\\right]\\right)}{\\sqrt{2} \\sqrt{\\pi} \\, {\\sigma}}\n",
    "\\end{equation}\n",
    "\n",
    "Apply the power rule: $[x^n]'=nx^{n-1}$\n",
    "\n",
    "\\begin{equation}\n",
    "= -\\frac{\\mathrm{e}^{-\\frac{x^{2}}{2{\\sigma}^{2}}} \\cdot 2x}{2^{\\frac{3}{2}} \\sqrt{\\pi} \\, {\\sigma}^{3}}\n",
    "\\end{equation}\n",
    "\n",
    "Finally, we simplify the expression obtaining the first derivative of the Gaussian function:\n",
    "\n",
    "\\begin{equation}\n",
    "= -\\frac{x\\mathrm{e}^{-\\frac{x^{2}}{2{\\sigma}^{2}}}}{\\sqrt{2} \\sqrt{\\pi} \\, {\\sigma}^{3}}\n",
    "\\end{equation}\n",
    "\n",
    "Now we can compute the second derivative:\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\mathrm{d}}{\\mathrm{d}x}\\left[-\\frac{x\\mathrm{e}^{-\\frac{x^{2}}{2{\\sigma}^{2}}}}{\\sqrt{2} \\sqrt{\\pi} \\, {\\sigma}^{3}}\\right]  \n",
    "\\end{equation}\n",
    "\n",
    "we can pull out the constant factor:\n",
    "\n",
    "\\begin{equation}\n",
    "= -\\frac{1}{\\sqrt{2} \\sqrt{\\pi} \\, {\\sigma}^{3}} \\cdot \\frac{\\mathrm{d}}{\\mathrm{d}x}\\left[x\\mathrm{e}^{-\\frac{x^{2}}{2{\\sigma}^{2}}}\\right]\n",
    "\\end{equation}\n",
    "\n",
    "The derivate of x is 1. For the exponential function we can apply the rule: $[e^{u(x)}]'=e^{u(x)}*u'(x)$\n",
    "\n",
    "\\begin{equation}\n",
    "= -\\frac{\\frac{\\mathrm{d}}{\\mathrm{d}x}\\left[x\\right] \\cdot \\mathrm{e}^{-\\frac{x^{2}}{2{\\sigma}^{2}}} + x \\cdot \\frac{\\mathrm{d}}{\\mathrm{d}x}\\left[\\mathrm{e}^{-\\frac{x^{2}}{2{\\sigma}^{2}}}\\right]}{\\sqrt{2} \\sqrt{\\pi} \\, {\\sigma}^{3}}\n",
    "\\end{equation}\n",
    "\n",
    "We can pull out the constant factor:\n",
    "\n",
    "\\begin{equation}\n",
    "= -\\frac{1\\mathrm{e}^{-\\frac{x^{2}}{2{\\sigma}^{2}}} + x\\mathrm{e}^{-\\frac{x^{2}}{2{\\sigma}^{2}}} \\cdot \\frac{\\mathrm{d}}{\\mathrm{d}x}\\left[-\\frac{x^{2}}{2{\\sigma}^{2}}\\right]}{\\sqrt{2} \\sqrt{\\pi} \\, {\\sigma}^{3}}\n",
    "\\end{equation}\n",
    "\n",
    "We derivate $x^2$ with the power rule: $[x^n]'=nx^{n-1}$\n",
    "\n",
    "\\begin{equation}\n",
    "= -\\frac{x\\mathrm{e}^{-\\frac{x^{2}}{2{\\sigma}^{2}}} \\left(-\\frac{1}{2{\\sigma}^{2}} \\cdot \\frac{\\mathrm{d}}{\\mathrm{d}x}\\left[x^{2}\\right]\\right) + \\mathrm{e}^{-\\frac{x^{2}}{2{\\sigma}^{2}}}}{\\sqrt{2} \\sqrt{\\pi} \\, {\\sigma}^{3}}\n",
    "\\end{equation}\n",
    "\n",
    "And we simplify the expression:\n",
    "\n",
    "\\begin{equation}\n",
    "= -\\frac{-\\frac{xx\\mathrm{e}^{-\\frac{x^{2}}{2{\\sigma}^{2}}} \\cdot 2}{2{\\sigma}^{2}} + \\mathrm{e}^{-\\frac{x^{2}}{2{\\sigma}^{2}}}}{\\sqrt{2} \\sqrt{\\pi} \\, {\\sigma}^{3}}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "= -\\frac{\\mathrm{e}^{-\\frac{x^{2}}{2{\\sigma}^{2}}} - \\frac{x^{2} \\mathrm{e}^{-\\frac{x^{2}}{2{\\sigma}^{2}}}}{{\\sigma}^{2}}}{\\sqrt{2} \\sqrt{\\pi} \\, {\\sigma}^{3}}\n",
    "\\end{equation}\n",
    "\n",
    "Now is possible to make other simplifications:\n",
    "\n",
    "\\begin{equation}\n",
    "= \\frac{\\left(x^{2} - {\\sigma}^{2}\\right) \\mathrm{e}^{-\\frac{x^{2}}{2{\\sigma}^{2}}}}{\\sqrt{2} \\sqrt{\\pi} \\, {\\sigma}^{5}}\n",
    "\\end{equation}\n",
    "\n",
    "-------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:21:50.067146Z",
     "start_time": "2024-10-24T12:21:50.064006Z"
    }
   },
   "outputs": [],
   "source": [
    "def laplace(sigma: int, filter_size: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Laplace 1D filter.\n",
    "\n",
    "    Args:\n",
    "        sigma (int): Standard deviation.\n",
    "        filter_size (int): Filter size.\n",
    "\n",
    "    Returns:\n",
    "        Lx (np.ndarray): Laplace filter.\n",
    "        x (np.ndarray): x values.\n",
    "    \"\"\"\n",
    "\n",
    "    #####################################################\n",
    "    ##                 YOUR CODE HERE                  ##\n",
    "    #####################################################\n",
    "\n",
    "    x = np.arange(-filter_size // 2, filter_size // 2 + 1)\n",
    "    Lx = np.zeros(x.shape[0])\n",
    "\n",
    "    for i, p in enumerate(np.nditer(x)):\n",
    "        Lx[i] = ((np.power(p, 2) - np.power(sigma, 2)) * (np.exp(-(np.power(p, 2)) / (2 * np.power(sigma, 2))))) / (\n",
    "                np.sqrt(2 * np.pi) * np.power(sigma, 5))\n",
    "\n",
    "    return Lx, x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "--------------------------------------------\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:21:50.149894Z",
     "start_time": "2024-10-24T12:21:50.068965Z"
    }
   },
   "outputs": [],
   "source": [
    "sigma = 3\n",
    "size = 61\n",
    "Lx, x = laplace(sigma, size)\n",
    "plt.figure(1)\n",
    "plt.plot(x, Lx, \".-\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### **1.1.3: An example of non-linear filter: 1-D median filter**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Up until now we have worked with linear 1-D filters, you are now asked to implement a non-linear one: the 1-D median filter.\n",
    "At each position $p$ of a given 1-D signal $\\mathcal{S}$, the median filter of size $s$ takes the neighborhood $\\mathcal{N}_s(p)=[\\mathcal{S}(p - \\frac{s - 1}{2}), \\mathcal{S}(p + \\frac{s - 1}{2})]$, and replaces the value of $p$ with the median of the values in $\\mathcal{N}_s(p)$.\n",
    "Since it removes outliers from $\\mathcal{N}_s(p)$, the median filter is often used in image and signal processing to remove noise.\n",
    "\n",
    "Complete the method below to compute the median filter $m(\\cdot)$ of size $s$ for all elements of a signal $\\mathcal{S}$.\n",
    "The method should return the filtered signal.\n",
    "From the description above, you may have noticed that one must *carefully* consider how to deal with the boundaries of the signal.\n",
    "In this exercise, you are free to choose the strategy to deal with the boundaries, you may look [here](https://en.wikipedia.org/wiki/Median_filter).\n",
    "\n",
    "You should get the following input-output pair:\n",
    "\n",
    "![1dmedian](./images/1dmedian.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:21:50.154087Z",
     "start_time": "2024-10-24T12:21:50.150677Z"
    }
   },
   "outputs": [],
   "source": [
    "def median_filter(signal: np.ndarray, filter_size: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Median 1D filter.\n",
    "    You are free to choose how to deal with the beginning and the end of the signal.\n",
    "    You can use the `np.median` function https://numpy.org/doc/stable/reference/generated/numpy.median.html\n",
    "\n",
    "    Args:\n",
    "        signal (np.ndarray): 1-D array of values\n",
    "        filter_size (int): size of the filter\n",
    "\n",
    "    Returns:\n",
    "        signal (np.ndarray): 1-D array of values with the median values computed at each position\n",
    "    \"\"\"\n",
    "    #####################################################\n",
    "    ##                 YOUR CODE HERE                  ##\n",
    "    #####################################################\n",
    "    # Ensure the size is odd\n",
    "    if filter_size % 2 == 0:\n",
    "        raise ValueError(\"Filter size must be odd.\")\n",
    "\n",
    "    # Define the half-window size\n",
    "    half_window = (filter_size - 1) // 2\n",
    "    signal_length = len(signal)\n",
    "\n",
    "    # Create an empty list for the filtered signal\n",
    "    filtered_signal = signal.copy()\n",
    "\n",
    "    # Loop through each position in the original signal\n",
    "    for i in range(signal_length):\n",
    "        # Calculate the neighborhood indices\n",
    "        start_index = max(0, i - half_window)\n",
    "        end_index = min(signal_length, i + half_window + 1)\n",
    "\n",
    "        # Extract the neighborhood\n",
    "        neighborhood = filtered_signal[start_index:end_index]\n",
    "\n",
    "        # Pad the neighborhood with edge values if it is not of size 'filter_size'\n",
    "        if len(neighborhood) < filter_size :\n",
    "            if start_index == 0:\n",
    "                neighborhood = np.append([0] * (filter_size - len(neighborhood)), neighborhood)\n",
    "            if end_index == signal_length:\n",
    "                neighborhood = np.append(neighborhood, [0] * (filter_size - len(neighborhood)))\n",
    "\n",
    "        # Sort the neighborhood to find the median\n",
    "        sorted_neighborhood = sorted(neighborhood)\n",
    "\n",
    "        # Compute the median\n",
    "        neighborhoodLen = len(sorted_neighborhood)\n",
    "        median_index = (neighborhoodLen - 1) // 2\n",
    "\n",
    "        filtered_signal[i] = sorted_neighborhood[median_index]\n",
    "\n",
    "    return filtered_signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "--------------------------------------------\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:21:50.519279Z",
     "start_time": "2024-10-24T12:21:50.154701Z"
    }
   },
   "outputs": [],
   "source": [
    "filter_size = 3\n",
    "signal = lambda x: 2 * np.sin(x) + np.sin(3 * x) + 0.5 * np.sin(7 * x)\n",
    "x = np.linspace(0, 50, 200)\n",
    "in_signal = signal(x)\n",
    "out_signal = median_filter(in_signal.copy(), filter_size)\n",
    "fig, axs = plt.subplots(2)\n",
    "fig.suptitle(\"Median filter\")\n",
    "axs[0].plot(x, in_signal, \".-\", label=\"$\\\\mathcal{S}$\", color=\"blue\")\n",
    "axs[0].grid()\n",
    "axs[0].legend()\n",
    "axs[1].plot(x, out_signal, \".-\", label=\"$m(\\\\mathcal{S})$\", color=\"red\")\n",
    "axs[1].grid()\n",
    "axs[1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### **1.1.4: Check linearity of the filters**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In *Question 1.0: warmup* we have seen some of the properties of linear operators and we have proven the additivity property of convolution.\n",
    "Consider the 1-D Gaussian filter $g(\\cdot)$, the 1-D Laplacian filter $l(\\cdot)$, and the 1-D median filter $m(\\cdot)$.\n",
    "You are given signals $\\mathcal{S}_1$ and $\\mathcal{S}_2$, by taking advantage of the functions you have implemented in the previous exercises, empirically verify the following:\n",
    "\n",
    "1. $g(\\mathcal{S}_1 + \\mathcal{S}_2) = g(\\mathcal{S}_1) + g(\\mathcal{S}_2)$\n",
    "2. $l(\\mathcal{S}_1 + \\mathcal{S}_2) = l(\\mathcal{S}_1) + l(\\mathcal{S}_2)$\n",
    "3. $g(l(\\mathcal{S}_1 + \\mathcal{S}_2)) = (g * l) * \\mathcal{S}_1 + (g * l) * \\mathcal{S}_2$\n",
    "4. $m(\\mathcal{S}_1 + \\mathcal{S}_2) \\neq m(\\mathcal{S}_1) + m(\\mathcal{S}_2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "*HINT: you can exploit the function `convolve1d` from `scipy.signal` to compute the convolution with the Gaussian and the Laplacian filters.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:21:50.527035Z",
     "start_time": "2024-10-24T12:21:50.520069Z"
    }
   },
   "outputs": [],
   "source": [
    "x = np.linspace(0, 50, 200)\n",
    "s1 = 2 * np.sin(x) + np.sin(3 * x) + 0.5 * np.sin(7 * x)\n",
    "s2 = 2 * np.cos(x) + np.cos(3 * x) + 0.5 * np.cos(7 * x)\n",
    "sigma, filter_size = 1, 7\n",
    "\n",
    "#####################################################\n",
    "##                 YOUR CODE HERE                  ##\n",
    "#####################################################\n",
    "import scipy.signal as scs\n",
    "\n",
    "g_s1_s2 = scs.convolve(s1 + s2, gauss(sigma, filter_size)[0])\n",
    "g_s1_g_s2 = scs.convolve(s1, gauss(sigma, filter_size)[0]) + scs.convolve(s2, gauss(sigma, filter_size)[0])\n",
    "l_s1_s2 = scs.convolve(s1 + s2, laplace(sigma, filter_size)[0])\n",
    "l_s1_l_s2 = scs.convolve(s1, laplace(sigma, filter_size)[0]) + scs.convolve(s2, laplace(sigma, filter_size)[0])\n",
    "g_l_s1_s2 = scs.convolve(scs.convolve(s1 + s2, laplace(sigma, filter_size)[0]), gauss(sigma, filter_size)[0])\n",
    "g_l_s1_g_l_s2 = scs.convolve(scs.convolve(gauss(sigma, filter_size)[0], laplace(sigma, filter_size)[0]),\n",
    "                             s1) + scs.convolve(\n",
    "    scs.convolve(gauss(sigma, filter_size)[0], laplace(sigma, filter_size)[0]), s2)\n",
    "m_s1_s2 = median_filter(s1 + s2, filter_size)\n",
    "m_s1_m_s2 = median_filter(s1, filter_size) + median_filter(s2, filter_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "--------------------------------------------\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:34:20.700465Z",
     "start_time": "2024-10-24T12:34:20.697837Z"
    }
   },
   "outputs": [],
   "source": [
    "assert np.allclose(g_s1_s2, g_s1_g_s2), \"Equation (1) is not verified\"\n",
    "assert np.allclose(l_s1_s2, l_s1_l_s2), \"Equation (2) is not verified\"\n",
    "assert np.allclose(g_l_s1_s2, g_l_s1_g_l_s2), \"Equation (3) is not verified\"\n",
    "assert not np.allclose(m_s1_s2, m_s1_m_s2), \"Equation (4) is not verified\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:33:24.471387Z",
     "start_time": "2024-10-24T12:33:24.028095Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(5, 1)\n",
    "fig.suptitle(\"Check linearity of the filters\")\n",
    "ys = [s1, s2, g_s1_s2, g_s1_g_s2, l_s1_s2, l_s1_l_s2, g_l_s1_s2, g_l_s1_g_l_s2, m_s1_s2, m_s1_m_s2]\n",
    "labels = [\"$\\\\mathcal{S}_1$\", \"$\\\\mathcal{S}_2$\", \"$g(\\\\mathcal{S}_1 + \\\\mathcal{S}_2)$\", \"$g(\\\\mathcal{S}_1) + g(\\\\mathcal{S}_2)$\", \"$l(\\\\mathcal{S}_1 + \\\\mathcal{S}_2)$\", \"$l(\\\\mathcal{S}_1) + l(\\\\mathcal{S}_2)$\", \"$g(l(\\\\mathcal{S}_1 + \\\\mathcal{S}_2))$\", \"$(g * l) * \\\\mathcal{S}_1 + (g * l) * \\\\mathcal{S}_2$\", \"$m(\\\\mathcal{S}_1 + \\\\mathcal{S}_2)$\", \"$m(\\\\mathcal{S}_1) + m(\\\\mathcal{S}_2)$\"]\n",
    "colors = [\"blue\", \"green\", \"red\", \"gray\", \"purple\", \"gray\", \"orchid\", \"gray\", \"orange\", \"gray\"]\n",
    "for y_idx in range(0, len(ys), 2):\n",
    "    i = y_idx // 2\n",
    "    x = np.arange(ys[y_idx].shape[0])\n",
    "    axs[i].plot(x, ys[y_idx], \".-\", label=labels[y_idx], color=colors[y_idx])\n",
    "    axs[i].plot(x, ys[y_idx + 1], \"--\", label=labels[y_idx + 1], color=colors[y_idx + 1])\n",
    "    axs[i].grid()\n",
    "    axs[i].legend(loc=\"upper right\")\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Why is that for the median filter $m(\\mathcal{S}_1 + \\mathcal{S}_2) \\neq m(\\mathcal{S}_1) + m(\\mathcal{S}_2)$?**\n",
    "\n",
    "-------------------------------------------------------\n",
    "\n",
    "**WRITE YOU ANSWER HERE**\n",
    "\n",
    "They are different as the median filter is a non-linear filter. A linear filter should satisfy additivity, homogeneity, and superposition properties. The median filter does not satisfy the additivity property because the median of the sum of two signals is not equal to the sum of the medians of those signals.\n",
    "\n",
    "-------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### **1.1.5: Butterworth Filter**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The Butterworth filter is a type of frequency domain filter characterized by a smooth transition between passband and stopband.\n",
    "    It is commonly used in signal processing to filter out frequencies beyond a certain cutoff, while maintaining a relatively flat frequency response in the passband.\n",
    "    The sharpness of the cutoff is controlled by the order of the filter (n).\n",
    "\n",
    "\\begin{equation}\n",
    "H(x) = \\frac{1}{1 + \\left( \\frac{x}{\\text{cutoff}} \\right)^{2n}}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "With $\\verb|cutoff|=20$ , $\\verb|filtersize|=30$ and $n=2$ you shouls expect the following output:\n",
    "\n",
    "![1dbutterworth](./images/Butterworth_Filter.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:21:50.967749Z",
     "start_time": "2024-10-24T12:21:50.964205Z"
    }
   },
   "outputs": [],
   "source": [
    "def butterworth_filter_1d(cutoff: float, filter_size: int, n: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Implements a 1D Butterworth filter.\n",
    "\n",
    "    Args:\n",
    "        cutoff (float): The frequency cutoff point. Determines the transition point between passband and stopband.\n",
    "        filter_size (int): Size of the filter. The filter will have `filter_size` elements symmetrically centered around zero.\n",
    "        n (int): The order of the Butterworth filter. Higher values result in a sharper transition between passband and stopband.\n",
    "\n",
    "    Returns:\n",
    "        Hx (np.ndarray): The 1D Butterworth filter coefficients.\n",
    "        x (np.ndarray): The x values corresponding to the filter, centered around zero.\n",
    "\n",
    "    \"\"\"\n",
    "    #####################################################\n",
    "    ##                 YOUR CODE HERE                  ##\n",
    "    #####################################################\n",
    "\n",
    "    x = np.arange(-filter_size // 2, filter_size // 2 + 1)\n",
    "    Hx = 1 / (1 + np.power(x / cutoff, 2 * n))\n",
    "    return Hx, x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "--------------------------------------------\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:21:51.074482Z",
     "start_time": "2024-10-24T12:21:50.968443Z"
    }
   },
   "outputs": [],
   "source": [
    "cutoff = 20.0\n",
    "filter_size = 30\n",
    "n = 2\n",
    "\n",
    "# Generate the Butterworth filter\n",
    "Hx, x = butterworth_filter_1d(cutoff, filter_size, n)\n",
    "\n",
    "# Plot the Butterworth filter\n",
    "plt.figure(1)\n",
    "plt.plot(x, Hx, \".-\")\n",
    "plt.title(\"1D Butterworth Filter\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"Hx\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### **1.2: 2D Filters *(3 Points)***\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### **2-D Laplacian filter**\n",
    "\n",
    "The function should take an image as input and return the result of the convolution of the image with a 2-D Laplacian kernel.\n",
    "You can use Python’s `convolve2D` function if you don’t want to implement it yourself.\n",
    "\n",
    "See the figure below for an illustration of Laplacian filtering.\n",
    "\n",
    "![](./images/stella_laplace.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:21:51.078484Z",
     "start_time": "2024-10-24T12:21:51.075458Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def laplacefiltering2D(img: np.ndarray, sigma: int, filter_size: int = 3) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Implement a 2D Laplacian of Gaussian filter.\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): Input image.\n",
    "        sigma (int): Standard deviation.\n",
    "        filter_size (int): Filter size.\n",
    "\n",
    "    Returns:\n",
    "        smooth_img (np.ndarray): Smoothed image.\n",
    "    \"\"\"\n",
    "    # # Get the 1D Laplacian of Gaussian filter\n",
    "    # lap_1d, _ = laplace(sigma, filter_size )\n",
    "\n",
    "    # # Create a 2D Laplacian of Gaussian filter by taking the outer product\n",
    "    # lap_2d = np.outer(lap_1d, np.transpose(lap_1d))\n",
    "\n",
    "    # # Normalize the 2D filter\n",
    "    # # lap_2d = lap_2d / np.sum(np.abs(lap_2d))\n",
    "\n",
    "    # # Apply the 2D Laplacian filter to the image\n",
    "    # smooth_img = convolve2d(img, lap_2d, mode='same', boundary='symm')\n",
    "\n",
    "    x = np.arange(-filter_size // 2, filter_size // 2 + 1)\n",
    "    y = np.arange(-filter_size // 2, filter_size // 2 + 1)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    \n",
    "    # Compute r_squared = x^2 + y^2\n",
    "    r_squared = X**2 + Y**2\n",
    "    \n",
    "    # Compute the Laplacian of Gaussian (LoG) using the formula\n",
    "    log_kernel = ((r_squared - 2 * sigma**2) / sigma**4) * np.exp(-r_squared / (2 * sigma**2))\n",
    "    \n",
    "    return convolve2d(img, log_kernel, mode='same')\n",
    "    # return smooth_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "--------------------------------------------\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:21:51.814856Z",
     "start_time": "2024-10-24T12:21:51.079679Z"
    }
   },
   "outputs": [],
   "source": [
    "img = rgb2gray(np.array(Image.open(\"./images/stella.jpg\")))\n",
    "smooth_img = laplacefiltering2D(img, 3, 18)\n",
    "\n",
    "imgs = [img, smooth_img]\n",
    "labels = [\"Input Image\", \"Laplacian Filtered Image\"]\n",
    "\n",
    "plot_pictures(imgs, labels, nrows=1, ncols=2, cmap=\"gray\", vmin=None, vmax=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### **2-D Box filter**\n",
    "\n",
    "The function should take an image as input and return the result of the convolution of this image with a 2D Box kernel.\n",
    "Beware of errors in the following code, find them, and correct them.\n",
    "You will be provided with the image to which the correct box filter has already been applied and you can use the SSIM metric to check that your result is correct, $SSIM \\approx 1$ means that it is correct.\n",
    "\n",
    "See the figure below for an illustration of Box filtering.\n",
    "\n",
    "![](./images/box_image.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:21:51.817978Z",
     "start_time": "2024-10-24T12:21:51.815795Z"
    }
   },
   "outputs": [],
   "source": [
    "def boxfiltering(img: np.ndarray, filter_size: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Implement a 2D Box filter.\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): Input image.\n",
    "        filter_size (int): Filter size.\n",
    "\n",
    "    Returns:\n",
    "        smooth_img (np.ndarray): Smoothed image.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    #####################################################\n",
    "    ##                 YOUR CODE HERE                  ##\n",
    "    #####################################################\n",
    "    boxFilter = box(filter_size)[0]\n",
    "    smooth_img = convolve2d(img, np.outer(boxFilter, np.transpose(boxFilter)), mode='same')\n",
    "\n",
    "    return smooth_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "--------------------------------------------\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:21:52.802237Z",
     "start_time": "2024-10-24T12:21:51.818620Z"
    }
   },
   "outputs": [],
   "source": [
    "img = rgb2gray(np.array(Image.open(\"./images/stella.jpg\")))\n",
    "smooth_img = np.load(\"assets/box_filter.npy\")\n",
    "smooth_fooled = boxfiltering(img, 20)\n",
    "\n",
    "\n",
    "imgs = [img, smooth_img, smooth_fooled]\n",
    "labels = [\"Input Image\", \"Box Filtered Image\", \"Box Filtered Image (Yours)\"]\n",
    "\n",
    "plot_pictures(imgs, labels, nrows=1, ncols=3, cmap=\"gray\", vmin=None, vmax=None)\n",
    "\n",
    "print(\n",
    "    f\"target_ssim_score:\\t{ssim(smooth_img, smooth_img, data_range=smooth_img.max() - smooth_img.min())}\\nyour_ssim_score:\\t{ssim(smooth_img, smooth_fooled, data_range=smooth_img.max() - smooth_img.min())}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "##### **Separability and computational efficiency**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "A separable filter is one that can be computed as $K(x,y) = f(x)f(y)$. Is the Laplacian of Gaussians filter separable?\n",
    "Remember that the Laplacian filter is $\\nabla^2 = \\frac{\\partial^2}{\\partial x^2} + \\frac{\\partial^2}{\\partial y^2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WRITE YOU ANSWER HERE**\n",
    "\n",
    "The separability of the Laplacian of Gaussian (LoG) can be shown by breaking it down into two parts: the **Gaussian** part and the **Laplacian** part.\n",
    "\n",
    "### Step 1: The Gaussian function\n",
    "The Gaussian function in 2D is given by:\n",
    "\n",
    "$$\n",
    "G(x, y) = \\frac{1}{2\\pi\\sigma^2} e^{-\\frac{x^2 + y^2}{2\\sigma^2}}\n",
    "$$\n",
    "\n",
    "This function is **separable**, meaning it can be written as the product of two 1D Gaussians:\n",
    "\n",
    "$$\n",
    "G(x, y) = G_x(x) G_y(y)\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "$$\n",
    "G_x(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma} e^{-\\frac{x^2}{2\\sigma^2}}\n",
    "\\quad \\text{and} \\quad\n",
    "G_y(y) = \\frac{1}{\\sqrt{2\\pi}\\sigma} e^{-\\frac{y^2}{2\\sigma^2}}\n",
    "$$\n",
    "\n",
    "Thus, the 2D Gaussian function can be separated into two 1D Gaussian functions in the \\(x\\) and \\(y\\) directions.\n",
    "\n",
    "### Step 2: The Laplacian operator\n",
    "The Laplacian operator in 2D is defined as the sum of the second-order partial derivatives with respect to \\(x\\) and \\(y\\):\n",
    "\n",
    "$$\n",
    "\\nabla^2 = \\frac{\\partial^2}{\\partial x^2} + \\frac{\\partial^2}{\\partial y^2}\n",
    "$$\n",
    "\n",
    "### Step 3: Applying the Laplacian to the Gaussian\n",
    "The Laplacian of Gaussian (LoG) is the result of applying the Laplacian operator to the 2D Gaussian function:\n",
    "\n",
    "$$\n",
    "\\text{LoG}(x, y) = \\nabla^2 G(x, y)\n",
    "$$\n",
    "\n",
    "This can be written as:\n",
    "\n",
    "$$\n",
    "\\text{LoG}(x, y) = \\frac{\\partial^2 G(x, y)}{\\partial x^2} + \\frac{\\partial^2 G(x, y)}{\\partial y^2}\n",
    "$$\n",
    "\n",
    "Since the Gaussian function is separable, i.e., \\(G(x, y) = G_x(x) G_y(y)\\), we can apply the Laplacian operator separately to each direction.\n",
    "\n",
    "1. **Second derivative with respect to \\(x\\):**\n",
    "   $$\n",
    "   \\frac{\\partial^2 G(x, y)}{\\partial x^2} = \\frac{\\partial^2}{\\partial x^2} \\left( G_x(x) G_y(y) \\right) = G_y(y) \\frac{\\partial^2 G_x(x)}{\\partial x^2}\n",
    "   $$\n",
    "\n",
    "2. **Second derivative with respect to \\(y\\):**\n",
    "   $$\n",
    "   \\frac{\\partial^2 G(x, y)}{\\partial y^2} = \\frac{\\partial^2}{\\partial y^2} \\left( G_x(x) G_y(y) \\right) = G_x(x) \\frac{\\partial^2 G_y(y)}{\\partial y^2}\n",
    "   $$\n",
    "\n",
    "Thus, the Laplacian of Gaussian becomes:\n",
    "\n",
    "$$\n",
    "\\text{LoG}(x, y) = G_y(y) \\frac{\\partial^2 G_x(x)}{\\partial x^2} + G_x(x) \\frac{\\partial^2 G_y(y)}{\\partial y^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Briefly explain why it is more convenient computationally speaking to use two 1D Laplacian filters rather than one 2D Laplacian filter.\n",
    "Assume that the dimension of the 2D Laplacian filter is $k^2$ and that the dimension of the two 1D Laplacian filters is $k$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "-------------------------------------------------------\n",
    "\n",
    "**WRITE YOU ANSWER HERE**\n",
    "\n",
    "Using two 1D Laplace filters instead of a single 2D Laplace filter is computationally more efficient because it reduces computational complexity. If the 2D Laplace filter has dimension $k x k$ , applying it to an image requires $O(k^2)$ operations for each pixel.\n",
    "\n",
    "In contrast, if we use two separable 1D Laplace filters, each of size $k$ , we apply the first filter along one direction (horizontal or vertical), and then apply the second filter along the other direction. This requires $O(k)$ operations for the first filter and additional $O(k)$ operations for the second filter, bringing the total to $O(2k)$, which is in the notation *O grande* is still remains $O(k)$ .\n",
    "\n",
    "Therefore, switching from a 2D filter to two separable 1D filters significantly reduces the computational complexity from an exponential $O(k^2)$ to a linear $O(k)$ complexity, especially for large filters.\n",
    "\n",
    "-------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### **Practical example of separability**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Up to this point, we have seen that both the Gaussian and the Laplacian operators are linear and you have explicitly proven that the Laplacian operator is separable.\n",
    "As you may guess, the Gaussian operator is also separable, and so is the composition of them: the Laplacian of Gaussian (LoG) operator.\n",
    "Recall from section section \"2-D Laplacian filter\" that the LoG operator is defined as:\n",
    "\n",
    "\\begin{equation}\n",
    "\\nabla^2 \\circ G = \\frac{d^2G(x)}{dx^2}=-\\frac{\\sigma^2 - x^2}{\\sqrt{2\\pi}\\sigma^5}\\exp\\left(-\\frac{x^2}{2\\sigma^2}\\right)\n",
    "\\end{equation}\n",
    "\n",
    "Previously, you have implemented a 2-D LoG filter without leveraging the separability property.\n",
    "In this section, you're asked to implement again the 2-D LoG filter **exploiting the separability**, i.e. convolving the image with a separable 1-D Laplacian kernel along axes.\n",
    "\n",
    "Compare the images to check that the separability property is valid. Note that the last image shows the differences between the separable case and the non separable case: it should be black up to numerical approximations, i.e. it should cointain approximately 0 everywhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:21:52.806721Z",
     "start_time": "2024-10-24T12:21:52.803340Z"
    }
   },
   "outputs": [],
   "source": [
    "def laplacefiltering(img: np.ndarray, sigma: int, filter_size: int = 3) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Implement a 2D Laplacian filter, leveraging the previous laplacian and the separability property.\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): Input image.\n",
    "        sigma (int): Standard deviation.\n",
    "        filter_size (int): Filter size.\n",
    "\n",
    "    Returns:\n",
    "        derived_img (np.ndarray): Derived image.\n",
    "    \"\"\"\n",
    "    # Get the 1D Laplacian filter\n",
    "    lap_1d, _ = laplace(sigma, filter_size)\n",
    "\n",
    "    # Normalize the filter\n",
    "    lap_1d = lap_1d / np.sum(np.abs(lap_1d))\n",
    "\n",
    "    # Apply the 1D Laplacian filter along the y-axis\n",
    "    img_x = convolve1d(img, lap_1d, axis=1)\n",
    "\n",
    "    # Apply the 1D Laplacian filter along the x-axis\n",
    "    img_y = convolve1d(img, lap_1d, axis=0)\n",
    "\n",
    "    return img_y + img_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "--------------------------------------------\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:21:53.699702Z",
     "start_time": "2024-10-24T12:21:52.807396Z"
    }
   },
   "outputs": [],
   "source": [
    "img = rgb2gray(np.array(Image.open(\"images/stella.jpg\")))\n",
    "derived_img_separable = laplacefiltering(img, sigma=3, filter_size=19)\n",
    "derived_img_non_separable = laplacefiltering2D(img, sigma=3, filter_size=19)\n",
    "def normalize(img):\n",
    "    return (img - img.min()) / (img.max() - img.min())\n",
    "derived_img_non_separable = normalize(derived_img_non_separable)\n",
    "derived_img_separable = normalize(derived_img_separable)\n",
    "difference_img = derived_img_separable - derived_img_non_separable\n",
    "\n",
    "plot_pictures(\n",
    "    [img/255, derived_img_separable, derived_img_non_separable, difference_img],\n",
    "    [\"Input Image\", \"Laplacian Filtered Image (separable case)\", \"Laplacian Filtered Image\", \"Difference image (separable - non separable)\"],\n",
    "    nrows=1,ncols=4,cmap=\"gray\",vmin=0,vmax=1\n",
    ")\n",
    "\n",
    "assert ssim(derived_img_separable, derived_img_non_separable, data_range=1) > 0.6, \"The separable and non-separable Laplacian filters are not the same.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### **Gaussian Blur Filter**\n",
    "\n",
    "Implement a 2D Gaussian filter.\n",
    "Make it so that the filter size changes adaptively with the size of sigma, and round it up to the nearest **odd** integer.\n",
    "$$\n",
    "\\verb|filter_size| = \\lceil 6\\sigma \\rceil\n",
    "$$\n",
    "\n",
    "See the figure below for an illustration of the blurring filter:\n",
    "\n",
    "![](./images/moon_gauss.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:21:53.703544Z",
     "start_time": "2024-10-24T12:21:53.700464Z"
    }
   },
   "outputs": [],
   "source": [
    "def gaussfiltering(img: np.ndarray, sigma: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Implement a 2D Gaussian filter, leveraging the previous gauss.\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): Input image.\n",
    "        sigma (int): Standard deviation.\n",
    "\n",
    "    Returns:\n",
    "        smooth_img (np.ndarray): Smoothed image.\n",
    "    \"\"\"\n",
    "\n",
    "    #####################################################\n",
    "    ##                 YOUR CODE HERE                  ##\n",
    "    #####################################################\n",
    "    filter_size = 6 * sigma\n",
    "\n",
    "    # if filter_size % 2 == 0:\n",
    "    #    filter_size += 1\n",
    "    \n",
    "\n",
    "    x, y = np.meshgrid(np.arange(-filter_size//2, filter_size//2+1),\n",
    "                       np.arange(-filter_size//2, filter_size//2+1))\n",
    "    gauss = 1 / 2 * np.pi * sigma ** 2 * np.exp(-(x ** 2 + y ** 2) / (2 * sigma ** 2))\n",
    "    normalized_gauss = gauss / np.sum(np.abs(gauss))\n",
    "\n",
    "    if img.ndim == 3:\n",
    "        out = np.zeros_like(img)\n",
    "        for i in range(3):\n",
    "            out[:,:,i] = convolve2d(img[:,:,i], normalized_gauss, mode='same')\n",
    "    else:\n",
    "        out = convolve2d(img, normalized_gauss, mode='same')\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "--------------------------------------------\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:21:56.329612Z",
     "start_time": "2024-10-24T12:21:53.704138Z"
    }
   },
   "outputs": [],
   "source": [
    "img = rgb2gray(np.array(Image.open(\"images/moon.jpg\")))\n",
    "imgs = [img, gaussfiltering(img, 10)]\n",
    "labels = [\"Input Image\", \"Gaussian Filtered Image\"]\n",
    "plot_pictures(imgs, labels, nrows=1, ncols=2, cmap=\"gray\", vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### **Discrete Laplacian Operator** \n",
    "\n",
    "Write the [discrete Laplacian filter](https://en.wikipedia.org/wiki/Discrete_Laplace_operator), which is a discrete approximation of the Laplacian Filter, speciic for image processing.\n",
    "\n",
    "Now, given an image $x$, a Gaussian filter $G(x)$ and a discrete Laplacian filter $L(x)$, compute:\n",
    "- $ G(L(x)) $\n",
    "- $ L(G(x)) $\n",
    "\n",
    "And check that the $SSIM = 1$\n",
    "\n",
    "See the figure below for illustration of the discrete Laplacian:\n",
    "\n",
    "![](./images/laplacian.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:21:56.410396Z",
     "start_time": "2024-10-24T12:21:56.330519Z"
    }
   },
   "outputs": [],
   "source": [
    "def discrete_laplace(img: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Discrete Laplacian operator.\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): Input image.\n",
    "\n",
    "    Returns:\n",
    "        Lap (np.ndarray): Image after applying the Laplacian operator.\n",
    "    \"\"\"\n",
    "    # Define the Laplacian kernel\n",
    "    laplacian_kernel = np.array([[0, 1, 0],\n",
    "                                 [1, -4, 1],\n",
    "                                 [0, 1, 0]])\n",
    "    \n",
    "    # Apply the discrete Laplacian filter using convolution\n",
    "    laplacian_image = convolve2d(img, laplacian_kernel, mode='same', boundary='symm')\n",
    "    \n",
    "    return laplacian_image\n",
    "\n",
    "\n",
    "img = rgb2gray(np.array(Image.open(\"./images/lenna.jpg\")))\n",
    "sigma = 1.0\n",
    "\n",
    "image_edges = discrete_laplace(img)\n",
    "image_edges_smoothed = gaussfiltering(image_edges, sigma)\n",
    "\n",
    "image_smoothed = gaussfiltering(img, sigma)\n",
    "image_smoothed_edges = discrete_laplace(image_smoothed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "--------------------------------------------\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:21:56.947219Z",
     "start_time": "2024-10-24T12:21:56.411303Z"
    }
   },
   "outputs": [],
   "source": [
    "# LoG\n",
    "imgs = [img, image_edges*5, image_edges_smoothed*10]\n",
    "labels = [\n",
    "    \"Input Image\",\n",
    "    \"Image with Laplacian Operator\",\n",
    "    \"Image with Laplacian-Gaussian Operator\",\n",
    "]\n",
    "plot_pictures(imgs, labels, nrows=1, ncols=3, cmap=\"gray\", vmin=0, vmax=255)\n",
    "\n",
    "# GoL\n",
    "imgs = [img, image_smoothed, image_smoothed_edges*10]\n",
    "labels = [\n",
    "    \"Input Image\",\n",
    "    \"Image with Gaussian Operator\",\n",
    "    \"Image with Gaussian-Laplacian Operator\",\n",
    "]\n",
    "plot_pictures(imgs, labels, nrows=1, ncols=3, cmap=\"gray\", vmin=0, vmax=255)\n",
    "\n",
    "\n",
    "assert ssim(\n",
    "            image_edges_smoothed,\n",
    "            image_smoothed_edges,\n",
    "            data_range=image_edges_smoothed.max() - image_edges_smoothed.min(),\n",
    "        ) > 0.9, \"The LoG and GoL operators should have similar results.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## **Question 2: Multi-Scale Image Representations** *(9 Points)*\n",
    "\n",
    "Edges represents object boundaries, thus edge detection is a very important preprocessing step for any object detection or recognition process.\n",
    "Simple edge detection kernels are based on approximation of gradient images.\n",
    "\n",
    "You will use some basic edge detection kernels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### **2.1: Prewitt Operator** *(2 points)*\n",
    "The [Prewitt operator](https://en.wikipedia.org/wiki/Prewitt_operator) is used in image processing, particularly within edge detection algorithms.\n",
    "Technically, it is a discrete differentiation operator, computing an approximation of the gradient of the image intensity function.\n",
    "\n",
    "See figure below for illustration of Prewitt operators in action:\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/3/3f/Bikesgray.jpg\" width=\"300\"/> <img src=\"https://upload.wikimedia.org/wikipedia/commons/3/3e/Bikesgray_prewitt.JPG\" width=\"300\"/>\n",
    "\n",
    "Now implement the Prewitt operators. Try to take advantage of the separability of this filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:21:56.953734Z",
     "start_time": "2024-10-24T12:21:56.950592Z"
    }
   },
   "outputs": [],
   "source": [
    "def prewitt_x(img: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Implement a 3x3 Prewitt discrete operator for vertical edges.\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): Input image.\n",
    "\n",
    "    Returns:\n",
    "        Fx (np.ndarray): Image with vertical edges.\n",
    "    \"\"\"\n",
    "    Mx = np.array([[1, 0, -1], [1, 0, -1], [1, 0, -1]])\n",
    "    out = convolve2d(img, Mx, mode='same')\n",
    "    \n",
    "    return out\n",
    "\n",
    "def prewitt_y(img: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Implement a 3x3 Prewitt discrete operator for horizontal edges.\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): Input image.\n",
    "\n",
    "    Returns:\n",
    "        Fx (np.ndarray): Image with horizontal edges.\n",
    "    \"\"\"\n",
    "    My = np.array([[1, 1, 1], [0, 0, 0], [-1, -1, -1]])\n",
    "    out = convolve2d(img, My, mode='same')\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "--------------------------------------------\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:21:57.192696Z",
     "start_time": "2024-10-24T12:21:56.954819Z"
    }
   },
   "outputs": [],
   "source": [
    "img = rgb2gray(np.array(Image.open(\"images/valve.png\")))\n",
    "imgs = [img, prewitt_x(img), prewitt_y(img)]\n",
    "labels = [\"Input Image\", \"Vertical Edges Detection\", \"Horizontal Edges Detection\"]\n",
    "plot_pictures(imgs, labels, nrows=1, ncols=3, cmap=\"gray\", vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Gradient Magnitude\n",
    "Using the previously defined functions `prewitt_x` and `prewitt_y`, retrieve the gradient magnitude of the image.\n",
    "\n",
    "See the figure below for an illustration of the Gradient Magnitude:\n",
    "\n",
    "![](./images/sobel.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:21:57.196421Z",
     "start_time": "2024-10-24T12:21:57.193740Z"
    }
   },
   "outputs": [],
   "source": [
    "def gradient_magnitude(img: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Apply the Prewitt operator to the image and compute\n",
    "    the gradient magnitude.\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): Input image.\n",
    "\n",
    "    Returns:\n",
    "        magnitude (np.ndarray): Gradient magnitude.\n",
    "    \"\"\"\n",
    "    #####################################################\n",
    "    ##                 YOUR CODE HERE                  ##\n",
    "    #####################################################\n",
    "    Gx = prewitt_x(img)\n",
    "    Gy = prewitt_y(img)\n",
    "    magnitude = np.copy(img)\n",
    "    \n",
    "    for i in range(img.shape[0]-2):\n",
    "        for j in range(img.shape[1]-2):\n",
    "            magnitude[i+1,j+1] = np.sqrt(Gx[i,j]**2 + Gy[i,j]**2)\n",
    "    \n",
    "    return magnitude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "--------------------------------------------\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:21:57.730246Z",
     "start_time": "2024-10-24T12:21:57.197104Z"
    }
   },
   "outputs": [],
   "source": [
    "img = rgb2gray(np.array(Image.open(\"images/valve.png\")))\n",
    "igms = [img, gradient_magnitude(img)]\n",
    "labels = [\"Input Image\", \"Gradient Magnitude\"]\n",
    "plot_pictures(igms, labels, nrows=1, ncols=2, cmap=\"gray\", vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### **2.2 Canny Edge Detector and Template Matching** *(4 points)*\n",
    "The Canny edge detector is an edge detection operator that uses a multi-stage algorithm to detect a wide range of edges in images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The Canny edge detection algorithm is composed of 5 steps:\n",
    "\n",
    "1. Noise reduction: apply Gaussian filter to smooth the image in order to remove the noise\n",
    "2. Gradient calculation: find the intensity gradients of the image\n",
    "3. Non-maximum suppression: apply gradient magnitude thresholding or lower bound cut-off suppression to get rid of spurious response to edge detection\n",
    "4. Double threshold: apply double threshold to determine potential edges\n",
    "5. Edge Tracking by Hysteresis: track edge by hysteresis: finalize the detection of edges by suppressing all the other edges that are weak and not connected to strong edges.\n",
    "\n",
    "\n",
    "You can learn more about the Canny edge detector at the following links:\n",
    "- [Canny Edge Detection](https://docs.opencv.org/4.x/da/d22/tutorial_py_canny.html).\n",
    "- [Canny Edge Detection Step by Step in Python — Computer Vision](https://towardsdatascience.com/canny-edge-detection-step-by-step-in-python-computer-vision-b49c3a2d8123).\n",
    "- [What is a Canny Edge Detection Algorithm?](https://towardsai.net/p/computer-vision/what-is-a-canny-edge-detection-algorithm)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### **Stage 1** - *Noise reduction*\n",
    "\n",
    "Apply Gaussian filter to smooth the image in order to remove the noise.\n",
    "**You just need to run the code for this stage**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "--------------------------------------------\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:21:57.941929Z",
     "start_time": "2024-10-24T12:21:57.730897Z"
    }
   },
   "outputs": [],
   "source": [
    "# STEP 1:\n",
    "img = rgb2gray(np.array(Image.open(\"images/pinwheel.jpg\")))\n",
    "smoothed_img = gaussfiltering(img, sigma=1)\n",
    "\n",
    "plot_pictures([img, smoothed_img], [\"Input image\", \"Smoothed image\"], 1, 2, vmax=255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### **Stage 2** - *Gradient calculation*\n",
    "\n",
    "This step detects edges intensity and direction by calculating the gradient of the image through edge detection operators.\n",
    "\n",
    "Edges correspond to a change of pixels’ intensity, the easiest way to detect it is applying filters that highlight it in both directions: horizontal ($x$) and vertical ($y$).\n",
    "\n",
    "When the image is smoothed, the derivatives $D_x(I)$ and $D_y(I)$ w.r.t. $x$ and $y$ are calculated.\n",
    "It can be implemented by convolving $I$ with Prewitt kernels $K_x$ and $K_y$, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Taking advantage of the functions `prewitt_x` and `prewitt_y` you have previously implemented, compute the gradient magnitude and direction of the image.\n",
    "Your function will output the magnitude $G$ and the slope $\\theta$ of the gradient.\n",
    "Scale the magnitude to the range $[0,255]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:21:57.945605Z",
     "start_time": "2024-10-24T12:21:57.942664Z"
    }
   },
   "outputs": [],
   "source": [
    "# STEP 2\n",
    "def prewitt_filters(img: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    This function applies the prewitt filter to the input image in x and y direction.\n",
    "    Scale    the magnitude to [0, 255] and return the magnitude and the direction of the gradient.\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): input image\n",
    "\n",
    "    Returns:\n",
    "        G (np.ndarray): gradient magnitude\n",
    "        theta (np.ndarray): gradient direction\n",
    "    \"\"\"\n",
    "\n",
    "    #####################################################\n",
    "    ##                 YOUR CODE HERE                  ##\n",
    "    #####################################################\n",
    "    Gx = prewitt_x(img)\n",
    "    Gy = prewitt_y(img)\n",
    "\n",
    "    # Compute the gradient magnitude\n",
    "    G = np.sqrt(Gx**2 + Gy**2)\n",
    "\n",
    "    # Normalize the gradient magnitude to the range [0, 255]\n",
    "    G = (G / G.max()) * 255\n",
    "\n",
    "    # Compute the gradient direction\n",
    "    theta = np.arctan2(Gy, Gx)\n",
    "\n",
    "    return (G, theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "--------------------------------------------\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:21:58.176276Z",
     "start_time": "2024-10-24T12:21:57.946958Z"
    }
   },
   "outputs": [],
   "source": [
    "G, theta = prewitt_filters(smoothed_img)\n",
    "\n",
    "plot_pictures([G, theta], [\"Gradient magnitude\", \"Gradient direction\"], 1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### **Stage 3** - *Non-maximum suppression*\n",
    "\n",
    "The image is scanned along the image gradient direction and, if pixels are not part of the local maxima, they are set to zero.\n",
    "This has the effect of suppressing all image information that is not part of local maxima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:21:58.181773Z",
     "start_time": "2024-10-24T12:21:58.177014Z"
    }
   },
   "outputs": [],
   "source": [
    "def direction_scan(\n",
    "    img: np.ndarray, theta: float, i:int, j:int\n",
    "    ) -> List[float]:\n",
    "    \"\"\"\n",
    "    This function quantizes the gradient directions into\n",
    "    four discrete directions:\n",
    "        - horizontal: theta in [0, 22.5) or [157.5, 180]\n",
    "        - right diagonal: theta in [22.5, 67.5)\n",
    "        - vertical: theta in [67.5, 112.5)\n",
    "        - left diagonal: theta in [112.5, 157.5)\n",
    "    then it returns the pixel values of the two pixels in\n",
    "    the corresponding direction.\n",
    "\n",
    "    Returns:\n",
    "        neighbors List[float]: pixel values of the two neighbors\n",
    "            in the corresponding direction\n",
    "    \"\"\"\n",
    "    #####################################################\n",
    "    ##            FIX THIS CODE (8 ERRORS)             ##\n",
    "    #####################################################\n",
    "    angle = theta[i, j] * 180.0 / np.pi  # Convert radians to degrees\n",
    "    angle = angle if angle >= 0 else angle + 180  # Ensure angle is positive\n",
    "\n",
    "    if (0 <= angle < 22.5) or (157.5 <= angle <= 180):\n",
    "        neighbors = [(i, j+1), (i, j-1)]  # horizontal\n",
    "    elif (22.5 <= angle < 67.5):\n",
    "        neighbors = [(i+1, j+1), (i-1, j-1)]  # right diagonal\n",
    "    elif (67.5 <= angle < 112.5):\n",
    "        neighbors = [(i+1, j), (i-1, j)]  # vertical\n",
    "    else:\n",
    "        neighbors = [(i+1, j-1), (i-1, j+1)]  # left diagonal\n",
    "\n",
    "    N, M = img.shape\n",
    "    pixels = [img[x, y] for x, y in neighbors if 0 <= x < N and 0 <= y < M]\n",
    "    return pixels\n",
    "\n",
    "def non_max_suppression(img: np.ndarray, D: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    This function performs non-maximum suppression on the input image.\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): input image\n",
    "        D (np.ndarray): gradient direction\n",
    "\n",
    "    Returns:\n",
    "        Z (np.ndarray): image after non-maximum suppression\n",
    "    \"\"\"\n",
    "\n",
    "    M, N = img.shape\n",
    "    Z = np.zeros((M, N), dtype=np.uint8)\n",
    "\n",
    "    for i in range(1, M - 1):\n",
    "        for j in range(1, N - 1):\n",
    "            # Get the two neighboring pixels in the gradient direction\n",
    "            neighbors = direction_scan(img, D, i, j)\n",
    "            \n",
    "            # Suppress the pixel if it's not a local maximum\n",
    "            if img[i, j] >= max(neighbors):\n",
    "                Z[i, j] = img[i, j]\n",
    "            else:\n",
    "                Z[i, j] = 0\n",
    " \n",
    "    return (Z / Z.max() * 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "--------------------------------------------\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:21:59.158995Z",
     "start_time": "2024-10-24T12:21:58.182607Z"
    }
   },
   "outputs": [],
   "source": [
    "Z = non_max_suppression(G, theta)\n",
    "\n",
    "plot_pictures(\n",
    "    [G, Z],\n",
    "    [\"Gradient magnitude\", \"Non-max suppressed magnitude\"],\n",
    "    1,\n",
    "    2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### **Stage 4** - *Thresholding*\n",
    "\n",
    "After application of non-maximum suppression, remaining edge pixels provide a more accurate representation of real edges in an image.\n",
    "However, some edge pixels remain that are caused by noise and color variation.\n",
    "To account for these spurious responses, it is essential to filter out edge pixels with a weak gradient value and preserve edge pixels with a high gradient value.\n",
    "\n",
    "This is accomplished by selecting high and low threshold values:\n",
    "- If an edge pixel’s gradient value is higher than the high threshold value, it is marked as a strong edge pixel.\n",
    "- If an edge pixel’s gradient value is smaller than the high threshold value and larger than the low threshold value, it is marked as a weak edge pixel.\n",
    "- If an edge pixel's gradient value is smaller than the low threshold value, it will be suppressed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Implement the function `threshold` that takes as input the image, the low and high threshold ratios and returns a tuple whose elements are the thresholded image, the value of the weak edges and the value of the strong edges. Set the value of weak edges to 100 and the value of strong edges to 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:21:59.163382Z",
     "start_time": "2024-10-24T12:21:59.159844Z"
    }
   },
   "outputs": [],
   "source": [
    "# STEP 4\n",
    "def threshold(\n",
    "    img: np.ndarray,\n",
    "    low_threshold: int = 100, high_threshold: int = 200,\n",
    "    weak_value :int = 100, strong_value: int = 255\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    This function applies a double thresholding to the input image.\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): input image\n",
    "        low_threshold (int): low threshold\n",
    "        high_threshold (int): high threshold\n",
    "        weak_value (int): value for weak edges\n",
    "        strong_value (int): value for strong edges\n",
    "\n",
    "    Returns:\n",
    "        res (np.ndarray): thresholded image\n",
    "    \"\"\"\n",
    "\n",
    "    i_height, i_width = img.shape\n",
    "    res = np.zeros((i_height, i_width), dtype=np.uint8)\n",
    "    \n",
    "    # Iterate over each pixel in the image\n",
    "    for i in range(i_height):\n",
    "        for j in range(i_width):\n",
    "            if img[i, j] >= high_threshold:\n",
    "                res[i, j] = strong_value\n",
    "            elif img[i, j] >= low_threshold:\n",
    "                res[i, j] = weak_value\n",
    "            else:\n",
    "                res[i, j] = 0\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "--------------------------------------------\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:21:59.480888Z",
     "start_time": "2024-10-24T12:21:59.164156Z"
    }
   },
   "outputs": [],
   "source": [
    "weak_value = 100\n",
    "strong_value = 255\n",
    "res = threshold(Z, low_threshold=25, high_threshold=100, weak_value=weak_value, strong_value=strong_value)\n",
    "\n",
    "plot_pictures(\n",
    "    [Z, res],\n",
    "    [\"Non-max suppressed magnitude\", \"Double-thresholded magnitude\"],\n",
    "    1,\n",
    "    2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### **Stage 5** - *Hysteresis*\n",
    "\n",
    "Based on the threshold results, the hysteresis consists of transforming weak pixels into strong ones, if and only if at least one of the pixels around the one being processed is a strong one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "--------------------------------------------\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:21:59.486117Z",
     "start_time": "2024-10-24T12:21:59.481939Z"
    }
   },
   "outputs": [],
   "source": [
    "# STEP 5\n",
    "def hysteresis(img: np.ndarray, weak: int = 100, strong: int = 255) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    This function applies hysteresis to the input image.\n",
    "\n",
    "    Args:\n",
    "        img (np.mdarray): input image.\n",
    "        weak (int): weak threshold.\n",
    "        strong (int): strong threshold.\n",
    "\n",
    "    Returns:\n",
    "        img (np.ndarray): image after hysteresis.\n",
    "    \"\"\"\n",
    "    M, N = img.shape\n",
    "    img_ = img.copy()\n",
    "    strong_edges_idxs = np.argwhere(img == strong).tolist()\n",
    "    while len(strong_edges_idxs) > 0:\n",
    "        i, j = strong_edges_idxs.pop()\n",
    "        if (i - 1 >= 0) and (j - 1 >= 0) and (i + 1 < M) and (j + 1 < N):\n",
    "            weak_edges_mask = img_[i - 1 : i + 2, j - 1 : j + 2] == weak\n",
    "            if np.any(weak_edges_mask):\n",
    "                img_[i - 1 : i + 2, j - 1 : j + 2][weak_edges_mask] = strong\n",
    "                weak_edges_idxs = (\n",
    "                    (np.argwhere(weak_edges_mask) - 1) + np.array([i, j])\n",
    "                ).tolist()\n",
    "                strong_edges_idxs = strong_edges_idxs + weak_edges_idxs[::-1]\n",
    "    img_[img_ != strong] = 0\n",
    "    return img_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:21:59.693905Z",
     "start_time": "2024-10-24T12:21:59.487046Z"
    }
   },
   "outputs": [],
   "source": [
    "final_img = hysteresis(res, weak=weak_value)\n",
    "\n",
    "plot_pictures(\n",
    "    [res, final_img],\n",
    "    [\"Double-thresholded magnitude\", \"Result after hysteresis\"],\n",
    "    1,\n",
    "    2,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### **Wrap up**\n",
    "Once you have seen how the Canny edge detector works step by step, implement the following `canny_edge_detector` function that wraps all the previous steps and returns the final image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:21:59.697861Z",
     "start_time": "2024-10-24T12:21:59.694646Z"
    }
   },
   "outputs": [],
   "source": [
    "def canny_edge_detector(\n",
    "    img: np.ndarray, sigma: int = 1,\n",
    "    low_threshold: int = 50, high_threshold: int = 100\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    This function implements the Canny edge detector.\n",
    "    Put together the previous functions to implement the\n",
    "    Canny edge detector.\n",
    "    Don't apply the gaussian filter if sigma=0.\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): input image\n",
    "        sigma (int): standard deviation for the gaussian filter;\n",
    "            if sigma=0, no gaussian filter is applied\n",
    "        low_threshold (int): low threshold\n",
    "        high_threshold (int): high threshold\n",
    "\n",
    "    Returns:\n",
    "        out_img (np.ndarray): image after applying the Canny edge\n",
    "            detector\n",
    "    \"\"\"\n",
    "    weak_value = 100\n",
    "\n",
    "    # Step 1: Noise reduction\n",
    "    if sigma != 0:\n",
    "        img = gaussfiltering(img, sigma)\n",
    "\n",
    "    # Step 2: Gradient calculation\n",
    "    G, theta = prewitt_filters(img)\n",
    "\n",
    "    # Step 3: Non-maximum suppression\n",
    "    Z = non_max_suppression(G, theta)\n",
    "\n",
    "    # Step 4: Double threshold\n",
    "    res = threshold(Z, low_threshold, high_threshold, weak_value, strong_value=255)\n",
    "\n",
    "    # Step 5: Edge tracking by hysteresis\n",
    "    out_img = hysteresis(res, weak=weak_value, strong=255)\n",
    "\n",
    "    return out_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "--------------------------------------------\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:22:00.896729Z",
     "start_time": "2024-10-24T12:21:59.698573Z"
    }
   },
   "outputs": [],
   "source": [
    "img = rgb2gray(np.array(Image.open(\"images/pinwheel.jpg\")))\n",
    "out_img = canny_edge_detector(img, sigma=2, low_threshold=35, high_threshold=100)\n",
    "\n",
    "plot_pictures(\n",
    "    [img, out_img],\n",
    "    [\"Input image\", \"Canny edge detector output\"],\n",
    "    1,\n",
    "    2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### **2.2.1: Template matching**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In this section, you are going to implement a template matching algorithm.\n",
    "The goal of template matching is to find the patch in the image that is most similar to a given template.\n",
    "In this exercise, you are going to use the Canny edge detector to extract the edges of the image and the template.\n",
    "Then, you will find the patch in the image that is most similar to the template.\n",
    "To choose the patch, you are asked to implement the [Jaccard Similarity](https://en.wikipedia.org/wiki/Jaccard_index) metric:\n",
    "\\begin{equation}\n",
    "\\mathrm{Jaccard}(I_{ij}, T)\n",
    "= \\frac{|I_{ij} \\cap T|}{|I_{ij} \\cup T|}\n",
    "%= \\frac{\\verb|sum|(I_{ij} \\land T)}{\\verb|sum|(I_{ij} \\lor T)}\n",
    "\\end{equation}\n",
    "\n",
    "In practice we can compute this by computing the ratio between the number of pixels where both $T$ and $I_{ij}$ have an edge and the number of pixels where $T$ or $I_{ij}$ have an edge.\n",
    "Note that $T$ denotes the template image, $I$ the target image, $I_{ij}$ a patch of $I$ at position $ij$ having the same dimensions of $T$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Implement the following function that takes as input the target image $I$, and the template image $T$. The returned values are a matrix of shape `(i_height-t_heigh, i_width-t_width)` containing the metric scores at each position and the indexes $(i,j)$ of the patch in $I$ with the best metric value, as depicted below. Note that $i$ indexes along the height of $I$, $j$ indexes along the width of $I$.\n",
    "\n",
    "```\n",
    "(i,j)-------width--------+\n",
    "  |                      |\n",
    "  |                      |\n",
    "height                   |\n",
    "  |                      |\n",
    "  |                      |\n",
    "  +----------------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:22:00.901595Z",
     "start_time": "2024-10-24T12:22:00.897603Z"
    }
   },
   "outputs": [],
   "source": [
    "def jaccard(patch:np.ndarray,template:np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    This function computes the Jaccard similarity between\n",
    "    two images.\n",
    "\n",
    "    Args:\n",
    "        patch (np.array): patch of the input image\n",
    "        template (np.array): template to match\n",
    "\n",
    "    Returns:\n",
    "        jaccard_score (float)\n",
    "    \"\"\"\n",
    "    intersection = np.sum((patch > 0) & (template > 0))  # Number of pixels where both have edges\n",
    "    union = np.sum((patch > 0) | (template > 0))         # Number of pixels where either have edges\n",
    "\n",
    "    # Avoid division by zero\n",
    "    # if union is 0, intersection will be 0 too\n",
    "    if union == 0:\n",
    "        return 0.0\n",
    "\n",
    "    jaccard_score = intersection / union\n",
    "    return jaccard_score\n",
    "\n",
    "def match_template(\n",
    "    img: np.ndarray, template: np.ndarray\n",
    ") -> Tuple[np.ndarray, Tuple[int, int]]:\n",
    "    \"\"\"\n",
    "    This function implements the template matching algorithm.\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): input image.\n",
    "        template (np.array): template to match.\n",
    "\n",
    "    Returns:\n",
    "        img_score (np.ndarray): metric scores after applying the template matching algorithm.\n",
    "        best_match_idxs (tuple): index of the best match.\n",
    "    \"\"\"\n",
    "    t_height, t_width = template.shape\n",
    "    i_height, i_width = img.shape\n",
    "    assert (i_height >= t_height) and (\n",
    "        i_width >= t_width\n",
    "    ), f\"Cannot match template of shape {template.shape} with image of shape {img.shape}\"\n",
    "    img_score = np.zeros((i_height - t_height + 1, i_width - t_width + 1))\n",
    "\n",
    "    # Loop over every possible patch in the image\n",
    "    for i in range(i_height - t_height + 1):\n",
    "        for j in range(i_width - t_width + 1):\n",
    "            patch = img[i:i + t_height, j:j + t_width]  # Extract patch from the image\n",
    "            img_score[i, j] = jaccard(patch, template)  # Compute Jaccard similarity\n",
    "    \n",
    "    # Find the indices of the best match (highest Jaccard score)\n",
    "    best_match_idxs = np.unravel_index(np.argmax(img_score), img_score.shape)\n",
    "\n",
    "    return img_score, best_match_idxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "--------------------------------------------\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "*Note: by running the following code, you should be able to detect the bigger Wally.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:22:03.374999Z",
     "start_time": "2024-10-24T12:22:00.902235Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "\n",
    "img_1 = rgb2gray(np.array(Image.open(\"images/wally.jpg\")))\n",
    "img_2 = rgb2gray(np.array(Image.open(\"images/findwally.jpg\")))\n",
    "\n",
    "template = canny_edge_detector(img_1, sigma=1.5, low_threshold=40, high_threshold=100)\n",
    "target = canny_edge_detector(img_2, sigma=1, low_threshold=25, high_threshold=100)\n",
    "\n",
    "imgs = [img_1, np.array(Image.open(\"images/findwally.jpg\")), img_2]\n",
    "xlabels = [\"Template\", \"Target\", \"Matched\"]\n",
    "axs = plot_pictures(imgs, xlabels, 1, 3, show=False, vmin=None, vmax=None)\n",
    "img_score, best_match = match_template(target, template)\n",
    "\n",
    "axs[-1].plot(best_match[1], best_match[0], \"ro\")\n",
    "axs[-1].add_patch(\n",
    "    patches.Rectangle(\n",
    "        (best_match[1], best_match[0]),\n",
    "        template.shape[1],\n",
    "        template.shape[0],\n",
    "        linewidth=1,\n",
    "        edgecolor=\"r\",\n",
    "        facecolor=\"none\",\n",
    "    )\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Here you can look at the template and at target image side by side, after having applied the Canny edge detector.\n",
    "Notice how they are different even though the parameters of the Canny edge detector are the same: this is due to the images not having the same background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:22:03.478072Z",
     "start_time": "2024-10-24T12:22:03.375783Z"
    }
   },
   "outputs": [],
   "source": [
    "imgs = [template, target]\n",
    "xlabels = [\"Template edges\", \"Target edges\"]\n",
    "plot_pictures(imgs, xlabels, 1, 2, show=True, cmap=\"gray\", same_scale=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### **2.3 Harris Corner Detector** (2 points)\n",
    "\n",
    "The Harris Corner Detector is a feature detection method used in computer vision to find corners, which are points with significant intensity changes in multiple directions. It works by analyzing image gradients to identify regions where shifting a small window results in large intensity variations. \n",
    "\n",
    "It can be considered a variation of the Canny Edge Detector. Implement it by leveraging the previously implemented functions.\n",
    "\n",
    "For more information: [link](https://en.wikipedia.org/wiki/Harris_corner_detector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:22:03.482404Z",
     "start_time": "2024-10-24T12:22:03.478951Z"
    }
   },
   "outputs": [],
   "source": [
    "def harris_corner_detector(\n",
    "    img: np.ndarray, \n",
    "    sigma: float = 1, \n",
    "    k: float = 0.04, \n",
    "    threshold: float = 1e-2) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Harris Corner Detector.\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): Input grayscale image.\n",
    "        sigma (float): Standard deviation for Gaussian smoothing.\n",
    "        k (float): Sensitivity factor to separate corners from edges.\n",
    "        threshold (float): Threshold for detecting corners.\n",
    "\n",
    "    Returns:\n",
    "        corners (np.ndarray): Image with corners marked.\n",
    "    \"\"\"\n",
    "    #####################################################\n",
    "    ##              COMPLETE THIS CODE                 ##\n",
    "    #####################################################\n",
    "    # Step 1: Smooth the image\n",
    "    img =  gaussfiltering(img, sigma) if sigma != 0 else img\n",
    "\n",
    "    # Step 2: Compute the gradients\n",
    "    dx = np.gradient(img, axis=1)\n",
    "    dy = np.gradient(img, axis=0)\n",
    "    dx2 = dx**2\n",
    "    dxy = dx*dy\n",
    "    dy2 = dy**2\n",
    "\n",
    "    # Step 3: Compute the sums of the products of gradients\n",
    "    window = np.ones((3, 3))\n",
    "    Sxx = convolve2d(dx2, window, mode='same')\n",
    "    Sxy = convolve2d(dxy, window, mode='same')\n",
    "    Syy = convolve2d(dy2, window, mode='same')\n",
    "\n",
    "    # Step 4: Compute the determinant and trace of the Harris matrix\n",
    "    det = Sxx * Syy - Sxy**2\n",
    "    trace = Sxx + Syy\n",
    "\n",
    "    # Step 5: Compute the Harris response\n",
    "    R = det - k * (trace**2)\n",
    "\n",
    "    corners = np.zeros_like(img)\n",
    "    corners[R > threshold * R.max()] = 255 \n",
    "    return corners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "--------------------------------------------\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:22:03.727855Z",
     "start_time": "2024-10-24T12:22:03.483327Z"
    }
   },
   "outputs": [],
   "source": [
    "img = rgb2gray(np.array(Image.open(\"images/pinwheel.jpg\")))\n",
    "imgs = [img, harris_corner_detector(img, 1)]\n",
    "labels = [\"Input Image\", \"Harris Corner Detector Image\"]\n",
    "plot_pictures(imgs, labels, nrows=1, ncols=2, cmap=\"grey\", vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### **2.4 Gaussian Pyramid** *(2 points)*\n",
    "\n",
    "Now let's implement a multi-scale object detection algorithm with Gaussian pyramid and template matching."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Gaussian Pyramid**\n",
    "\n",
    "Implement a downscaling function that makes use of the iterative approach described by the Gaussian Pyramid. Use [`skimage.transform.resize`](https://scikit-image.org/docs/stable/api/skimage.transform.html#skimage.transform.resize) to resize the image to a lower scale, but don't forget to first smooth the image.\n",
    "Repeat this process `step` times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:22:03.731461Z",
     "start_time": "2024-10-24T12:22:03.728534Z"
    }
   },
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "\n",
    "def downscale(\n",
    "    img: np.ndarray,\n",
    "    factor: float,\n",
    "    steps: int = 3,\n",
    "    sigma: float = 1\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Iteratively apply a gaussian blur to avoid aliasing\n",
    "    and then downscale the input image by the given factor.\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): Input image.\n",
    "        factor (float): Resizing factor, how may times smaller\n",
    "            is the image going to be.\n",
    "        steps(int): the number of times to repeat the iteration.\n",
    "        sigma (float): Standard deviation for the Gaussian filter.\n",
    "\n",
    "    Returns:\n",
    "        imgs (list): list of downscaled images. Each one is\n",
    "            \"factor\" times smaller then the previous.\n",
    "        blurred (list): list of blurred images produced in\n",
    "            the downscaling process.\n",
    "    \"\"\"\n",
    "    imgs = [img]\n",
    "    blurred = []\n",
    "\n",
    "    for _ in range(steps):\n",
    "        # Apply Gaussian blur\n",
    "        blurred_img = gaussfiltering(imgs[-1], sigma)\n",
    "        blurred.append(blurred_img)\n",
    "\n",
    "        # Downscale the image\n",
    "        downscaled_img = resize(blurred_img, \n",
    "                                (int(blurred_img.shape[0] / factor), \n",
    "                                 int(blurred_img.shape[1] / factor)), preserve_range=True)\n",
    "        imgs.append(downscaled_img)\n",
    "\n",
    "    return imgs, blurred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "--------------------------------------------\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:22:07.281052Z",
     "start_time": "2024-10-24T12:22:03.732446Z"
    }
   },
   "outputs": [],
   "source": [
    "img = rgb2gray(np.array(Image.open(\"images/coffee.jpg\")))\n",
    "STEPS = 3\n",
    "imgs, img_blur = downscale(img, 2, steps=STEPS, sigma=3)\n",
    "\n",
    "for i in range(STEPS+1):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(int(12* .8**(i+1)),int(8* .8**(i+1))))\n",
    "    plt.gray()\n",
    "    fig.tight_layout()\n",
    "    axes[0].imshow(imgs[i])\n",
    "    axes[0].set_title(f\"Resized image {imgs[i].shape}\" if i != 0 else \"Original Image\")\n",
    "    axes[0].axis('off')\n",
    "    if i < STEPS:\n",
    "        axes[1].imshow(img_blur[i])\n",
    "        axes[1].set_title(f\"Smooth image {img_blur[i].shape}\")\n",
    "    axes[1].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### **Aliasing**\n",
    "\n",
    "When an image is downscaled, some information is inevitably lost. If this process isn't handled carefully, it can lead to distortions such as jagged edges, moiré patterns, or a \"stair-step\" effect on diagonal lines. This kind of effect is called \"Aliasing\".\n",
    "\n",
    "![](https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2F1.bp.blogspot.com%2F-AWQvtxVtBBY%2FV9F03wJwAnI%2FAAAAAAAAA7A%2FVfGtkgT8O60Y9jBx5hXT1ixw4URaqxHWQCLcB%2Fs1600%2FSupersampling%252B2D%252Banti-aliasing.gif&f=1&nofb=1&ipt=0de5f53f14ec430997ea1d210e4f6ab6bcb5131861fe84ddeeb14e15be689527&ipo=images)\n",
    "\n",
    "These artifacts arise because the sampling rate of the new, smaller image is insufficient to accurately represent the high frequency details present in the original image. This is related to the Nyquist-Shannon sampling theorem, which states that to accurately represent a signal, the sampling rate must be at least twice the highest frequency present in the signal.\n",
    "To mitigate aliasing when downscaling, various techniques can be employed, such as applying low-pass filters before reducing the image size (i.e. a Gaussian blur).\n",
    "\n",
    "Now confront the results of downscaling with the gaussian pyramid that you just implemented against a naive resizing.\n",
    "\n",
    "--------------------------------------------\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:22:08.038670Z",
     "start_time": "2024-10-24T12:22:07.281840Z"
    }
   },
   "outputs": [],
   "source": [
    "img = np.array(Image.open(\"images/bricks.jpg\"))\n",
    "img_no_blur = np.array(Image.open(\"images/bricks.jpg\"))\n",
    "\n",
    "imgs, img_blur = downscale(img, 2, steps=STEPS, sigma=1)\n",
    "\n",
    "\n",
    "for i in range(3):\n",
    "    img = imgs[i+1]\n",
    "    img_no_blur = resize(img_no_blur, (img_no_blur.shape[0] //2, img_no_blur.shape[1] // 2))\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(int(12* .75**(i+1)),int(8* .8**(i+1))))\n",
    "    plt.gray()\n",
    "    fig.tight_layout()\n",
    "    axes[0].imshow(img.astype(int))\n",
    "    axes[0].set_title(f\"Downsampled image {img.shape[:2]}\\nwith Anti-aliasing\")\n",
    "    axes[0].axis('off')\n",
    "    axes[1].imshow(img_no_blur)\n",
    "    axes[1].set_title(f\"Downsampled image {img_no_blur.shape[:2]}\\nwithout blurring\")\n",
    "    axes[1].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**QUESTION**\n",
    "\n",
    "Which differences do you notice between the first and the second image?\n",
    "What is the cause of the Aliasing effect?\n",
    "\n",
    "-------------------------------------------------------\n",
    "\n",
    "\n",
    "Differences Between the Gaussian Pyramid and Naive Resizing:\n",
    "\n",
    "Smoothness of Edges:\n",
    "Gaussian Pyramid: The downscaled image with the Gaussian pyramid tends to have smoother edges. This is because the pyramid applies a low-pass filter (Gaussian blur) before resizing, which removes high-frequency details (sharp transitions).\n",
    "Naive Resizing: In naive resizing, there is no filtering step, so the edges can appear jagged and more prone to distortions like \"stair-step\" effects along diagonal lines.\n",
    "\n",
    "Reduction of Artifacts:\n",
    "Gaussian Pyramid: The Gaussian-filtered image generally avoids aliasing artifacts such as moiré patterns, jagged edges, and \"stair-steps\" because the high frequencies are smoothed out before reducing the size.\n",
    "Naive Resizing: Without applying a blur, naive resizing can result in significant aliasing, making patterns like fine textures or repeating elements in the image (such as lines or grids) distorted, causing unwanted visual effects.\n",
    "\n",
    "Cause of the Aliasing Effect:\n",
    "\n",
    "Aliasing occurs because of insufficient sampling when downscaling an image. According to the Nyquist-Shannon sampling theorem, the sampling rate (in this case, the number of pixels in the downscaled image) must be at least twice the highest frequency present in the original image to accurately capture its details.\n",
    "\n",
    "In naive resizing, high-frequency components (such as sharp edges or fine textures) are improperly sampled. This results in artifacts such as jagged lines and moiré patterns. Without a low-pass filter (like the Gaussian blur used in the Gaussian pyramid), these high-frequency details aren't smoothed out, leading to distortions when the image is resized.\n",
    "\n",
    "-------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### **2.5: Multi-Scale Template Matching (? Points)**\n",
    "Write a multi-scale object detection algorithm using the Gaussian Pyramid and the template matching algorithm you have implemented in the previous exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:44:53.728399Z",
     "start_time": "2024-10-24T12:44:53.722644Z"
    }
   },
   "outputs": [],
   "source": [
    "def multi_scale_match_template(\n",
    "    img: np.ndarray,\n",
    "    template: np.ndarray,\n",
    "    steps: int, factor: float = 2,\n",
    "    sigma: float = 1, \n",
    "    low_threshold: int = 30,\n",
    "    high_threshold: int = 70,\n",
    ") -> List[Dict[str, Union[np.ndarray, Tuple[int, int]]]]:\n",
    "    \"\"\"\n",
    "    This function implements the multi-scale template matching.\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): input image.\n",
    "        template (np.ndarray): template image.\n",
    "        steps (int): number of steps for the Pyramid.\n",
    "        sigma (float): the Gaussian filter parameter.\n",
    "        low_threshold (int): low threshold for Canny edge detector.\n",
    "        high_threshold (int): high threshold for Canny edge detector.\n",
    "\n",
    "    Returns:\n",
    "        out: list of dictionaries containing:\n",
    "            img_score (np.ndarray): score image.\n",
    "            result (Tuple[int, int]): best match coordinates.\n",
    "            template (np.ndarray): template image.\n",
    "    \"\"\"\n",
    "    # Initialize lists for storing results\n",
    "    score_results = []\n",
    "    templates = []\n",
    "    factor = 2\n",
    "    # Downscale the template\n",
    "    scaled_templates, _ = downscale(template, factor=factor, steps=steps, sigma=sigma)\n",
    "\n",
    "    # Perform template matching at each scale\n",
    "    for scale_idx in range(steps):\n",
    "        scaled_template = scaled_templates[scale_idx]\n",
    "\n",
    "        # Ensure the template is smaller than the image at this scale\n",
    "        if img.shape[0] >= scaled_template.shape[0] and img.shape[1] >= scaled_template.shape[1]:\n",
    "            # Use the template matching function (e.g., match_template) at this scale\n",
    "            img_canny = canny_edge_detector(img, sigma=sigma, low_threshold=low_threshold, high_threshold=high_threshold)\n",
    "            scaled_template_canny = canny_edge_detector(scaled_template, sigma=sigma, low_threshold=low_threshold, high_threshold=high_threshold)\n",
    "\n",
    "            score, best_match_coords = match_template(img_canny, scaled_template_canny)\n",
    "\n",
    "            # Store the results\n",
    "            score_results.append((score, best_match_coords))\n",
    "            templates.append(scaled_template)\n",
    "\n",
    "    out = [\n",
    "        {\"img_score\": score, \"result\": result, \"template\": t}\n",
    "        for (score, result), t in zip(score_results, templates)\n",
    "    ]\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "_____________________________________________________\n",
    "**Do not write below this line just run it**\n",
    "_____________________________________________________\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:48:50.081862Z",
     "start_time": "2024-10-24T12:48:20.134697Z"
    }
   },
   "outputs": [],
   "source": [
    "img1 = rgb2gray(np.array(Image.open(\"images/findwally.jpg\")))\n",
    "img2 = rgb2gray(np.array(Image.open(\"images/wally.jpg\")))\n",
    "\n",
    "multiscale_res = multi_scale_match_template(\n",
    "    img=img1,\n",
    "    template=img2,\n",
    "    steps=2,\n",
    "    sigma=1,\n",
    "    low_threshold=30,\n",
    "    high_threshold=70,\n",
    ")\n",
    "\n",
    "\n",
    "imgs = [img2, np.array(Image.open(\"images/findwally.jpg\"))]\n",
    "xlabels = [\n",
    "    \"Template\",\n",
    "    \"Matched\",\n",
    "]\n",
    "axs = plot_pictures(imgs, xlabels, 1, 2, show=False, vmin=None, vmax=None)\n",
    "\n",
    "for d in multiscale_res:\n",
    "    axs[-1].plot(d[\"result\"][1], d[\"result\"][0], \"ro\")\n",
    "    axs[-1].add_patch(\n",
    "        patches.Rectangle(\n",
    "            (d[\"result\"][1], d[\"result\"][0]),\n",
    "            d[\"template\"].shape[1]-2,\n",
    "            d[\"template\"].shape[0]-2,\n",
    "            linewidth=1,\n",
    "            edgecolor=\"r\",\n",
    "            facecolor=\"none\",\n",
    "        )\n",
    "    )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## **Question 3: Object Identification** *(12 Points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "*Note: This identification part contains **query and model images** for the evaluation, which correspond to the same set of objects photographed from different viewpoints. The files **model.txt** and **query.txt** contain lists of image files arranged so that i-th model image depicts the same object as i-th query image.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### **3.1: 3D Joint Color Histogram** *(2 points)*\n",
    "\n",
    "Your task is to implement a Python function, histogramdd, from scratch. This function should compute the multidimensional histogram of a given image. The function should accept an image and a specification for the number of bins to use for each dimension. You should then divide the data into bins and count the number of data points that fall into each bin.\n",
    "\n",
    "If you want to check that your result is correct, you can compare it with the [function already implemented by NumPy](https://numpy.org/doc/stable/reference/generated/numpy.histogramdd.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:22:36.729746Z",
     "start_time": "2024-10-24T12:22:36.725984Z"
    }
   },
   "outputs": [],
   "source": [
    "def histogramdd(img: np.ndarray, bins: int = 10) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Follow these steps:\n",
    "        1) Create bin intervals for each dimension.\n",
    "        2) Compute the shape of the histogram based on bin intervals.\n",
    "        3) Initialize the histogram as an array of zeros.\n",
    "        4) Compute the histogram for the input data.\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): Input image.\n",
    "        bins (int): Number of bins.\n",
    "\n",
    "    Returns:*1.0\n",
    "        histograms (np.ndarray): Histogram.\n",
    "        bin_edges (np.ndarray): Bin edges.\n",
    "    \"\"\"\n",
    "\n",
    "    #####################################################\n",
    "    ##                 YOUR CODE HERE                  ##\n",
    "    #####################################################\n",
    "    \n",
    "    # Create bin intervals for each dimension: take the min and max of each dimension and divide it into bins\n",
    "    bin_edges = [np.linspace(0, 255, bins + 1) for dim in range(img.shape[-1])]\n",
    "    \n",
    "    # Calculate the shape of the histogram (bins per dimension), in this case [bins, bins, bins]\n",
    "    histogram_shape = [bins] * img.shape[-1]\n",
    "\n",
    "    # Initialize the histogram array with zeros\n",
    "    histograms = np.zeros(histogram_shape, dtype=int)\n",
    "\n",
    "    # Compute the histogram for the input data.\n",
    "    # For each color channel, use np.digitize to determine which bin each pixel falls into\n",
    "    indices = np.stack([np.digitize(img[..., dim], bin_edges[dim]) - 1 for dim in range(img.shape[-1])], axis=-1)\n",
    "\n",
    "    # Ensure indices stay within valid bounds (i.e., between 0 and bins-1) [EX: if pixel value is 255 in 1D, it should be in the last bin of first dimension]\n",
    "    indices = np.clip(indices, 0, bins - 1)\n",
    "\n",
    "    # Compute the histogram by looping over all pixel values\n",
    "    for idx in indices.reshape(-1, img.shape[-1]):  # Flatten the image to loop over all pixel values\n",
    "        histograms[tuple(idx)] += 1  # Increment the corresponding count in the correct bin\n",
    "\n",
    "    return histograms, bin_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "--------------------------------------------\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:22:37.230071Z",
     "start_time": "2024-10-24T12:22:36.730568Z"
    }
   },
   "outputs": [],
   "source": [
    "def histogram3dplot(h, e, fig=None):\n",
    "    \"\"\"\n",
    "    Visualize a 3D histogram\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    h: histogram array of shape (M,N,O)\n",
    "    e: list of bin edge arrays (for R, G and B)\n",
    "    \"\"\"\n",
    "    M, N, O = h.shape  # numero di bins\n",
    "    idxR = np.arange(M)\n",
    "    idxG = np.arange(N)\n",
    "    idxB = np.arange(O)\n",
    "\n",
    "    R, G, B = np.meshgrid(idxR, idxG, idxB)  # divisione per bins\n",
    "    a = np.diff(e[0])[0]\n",
    "    b = a / 2\n",
    "    R = a * R + b\n",
    "\n",
    "    a = np.diff(e[1])[0]\n",
    "    b = a / 2\n",
    "    G = a * G + b\n",
    "\n",
    "    a = np.diff(e[2])[0]\n",
    "    b = a / 2\n",
    "    B = a * B + b\n",
    "\n",
    "    colors = np.vstack((R.flatten(), G.flatten(), B.flatten())).T / 255\n",
    "    h = h / np.sum(h)\n",
    "    if fig is not None:\n",
    "        f = plt.figure(fig)\n",
    "    else:\n",
    "        f = plt.gcf()\n",
    "    ax = f.add_subplot(111, projection=\"3d\")\n",
    "    mxbins = np.array([M, N, O]).max()\n",
    "    ax.scatter(\n",
    "        R.flatten(),\n",
    "        G.flatten(),\n",
    "        B.flatten(),\n",
    "        s=h.flatten() * (256 / mxbins) ** 3 / 2,\n",
    "        c=colors,\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel(\"Red\")\n",
    "    ax.set_ylabel(\"Green\")\n",
    "    ax.set_zlabel(\"Blue\")\n",
    "\n",
    "\n",
    "img = Image.open(\"images/colors.jpg\")\n",
    "img = np.array(img)\n",
    "h, e = histogramdd(img.reshape(-1, 3), bins=10)\n",
    "histogram3dplot(h, e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### **3.2: Types of Histograms** *(2 points)*\n",
    "\n",
    "In this section, you are asked to implement the **GB** histogram and to correct the dx/dy histogram. Finally, you are asked to comment and compare the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### **GB Histogram**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In this exercise, you should implement the **GB** histogram.\n",
    "\n",
    "*Note: as before, when considering GB, you should keep in mind that the range of the pixel's intensity is between $0$ and $255$*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:22:37.235559Z",
     "start_time": "2024-10-24T12:22:37.231161Z"
    }
   },
   "outputs": [],
   "source": [
    "def gb_hist_from_scratch(img_color_double: np.ndarray, num_bins: int = 5) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute the *joint* histogram for the G and B color channels in the image.\n",
    "    The histogram should be normalized so that sum of all values equals 1,\n",
    "    assume that values in each channel vary between 0 and 255\n",
    "\n",
    "    Args:\n",
    "        img_color_double (np.ndarray): Input color image.\n",
    "        num_bins (int): Number of bins used to discretize each channel, total number of bins in the histogram should be num_bins^2.\n",
    "\n",
    "    Returns:\n",
    "        hists (np.ndarray): Joint histogram.\n",
    "\n",
    "    E.g. hists[0,9] contains the number of image_color pixels such that:\n",
    "        - their G values fall in bin 0\n",
    "        - their B values fall in bin 9\n",
    "    \"\"\"\n",
    "\n",
    "    #####################################################\n",
    "    ##                 YOUR CODE HERE                  ##\n",
    "    #####################################################\n",
    "    G = img_color_double[:, :, 1]\n",
    "    B = img_color_double[:, :, 2]\n",
    "    \n",
    "    # Compute the bin edges (0 to 255, split into num_bins equal intervals)\n",
    "    bin_edges = np.linspace(0, 255, num_bins + 1)\n",
    "    \n",
    "    # Digitize the pixel values into corresponding bins for both G and B channels\n",
    "    G_bins = np.digitize(G, bin_edges) - 1  # -1 to shift to zero-based index\n",
    "    B_bins = np.digitize(B, bin_edges) - 1\n",
    "    \n",
    "    # Ensure that no bin index is out of bounds (clip values)\n",
    "    G_bins = np.clip(G_bins, 0, num_bins - 1)\n",
    "    B_bins = np.clip(B_bins, 0, num_bins - 1)\n",
    "    \n",
    "    # Create an empty histogram array with shape (num_bins, num_bins)\n",
    "    histograms = np.zeros((num_bins, num_bins), dtype=np.float64)\n",
    "    \n",
    "    # Populate the histogram by counting occurrences of (G_bin, B_bin) pairs\n",
    "    for i in range(G.shape[0]):\n",
    "        for j in range(G.shape[1]):\n",
    "            histograms[G_bins[i, j], B_bins[i, j]] += 1\n",
    "    \n",
    "    # Normalize the histogram so that the sum of all elements equals 1\n",
    "    histograms /= np.sum(histograms)\n",
    "    \n",
    "    return histograms.flatten()\n",
    "\n",
    "\n",
    "def gb_hist(img_color_double: np.ndarray, num_bins: int = 5) -> np.ndarray:\n",
    "    # Extract the G and B channels (assuming img_color_double is (H, W, 3) for RGB)\n",
    "    G_channel = img_color_double[..., 1]  # Green channel\n",
    "    B_channel = img_color_double[..., 2]  # Blue channel\n",
    "\n",
    "    # Stack the G and B channels into a 2D array\n",
    "    GB_image = np.stack([G_channel, B_channel], axis=-1)\n",
    "\n",
    "    # Compute the joint histogram using the histogramdd function\n",
    "    histograms, bin_edges = histogramdd(GB_image, bins=num_bins)\n",
    "\n",
    "    # Normalize the histogram so that the sum of all elements equals 1\n",
    "    histograms = histograms.astype(np.float64)  # Convert to float64 to avoid integer division\n",
    "    histograms /= np.sum(histograms)\n",
    "\n",
    "    # Flatten the 2D histogram into a 1D array\n",
    "    return histograms.flatten()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "--------------------------------------------\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:22:37.383992Z",
     "start_time": "2024-10-24T12:22:37.236427Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compose and test GB histograms (histogram_module.GB_hist)\n",
    "img_color = np.array(Image.open(\"images/superman.jpg\"))\n",
    "\n",
    "plt.figure(3, figsize=(16, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(img_color)\n",
    "\n",
    "num_bins_color = 5\n",
    "plt.subplot(1, 2, 2)\n",
    "hist_gb = gb_hist(img_color.astype(\"double\"), num_bins_color)\n",
    "plt.bar(np.array(range(1, hist_gb.size + 1)), hist_gb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### **DX/DY Histogram**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In this exercise, you will find an implemented version of another type of histogram, the dx/dy one. However, **it is not correct, there are some mistakes in the code**:\n",
    "\n",
    "- function `gaussdx`: **2 mistakes**;\n",
    "- function `gauss_dxdy`: **2 mistakes**;\n",
    "- function `hist_dxdy`: **2 mistakes**.\n",
    "\n",
    "You are asked to copy each function in the corresponding cell and to correct the mistakes. Put a comment on the lines where you have made the corrections.\n",
    "Before coding, write down the first derivative of the Gaussian function.\n",
    "\n",
    "*HINT: leverage the result of the derivation to correct the mistakes in `gaussdx`*.\n",
    "\n",
    "*Note: each mistaken line counts as one mistake; a mistake can also be a missing line or a missing block of lines*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "-------------------------------------------------------\n",
    "\n",
    "\n",
    "**WRITE YOU ANSWER HERE**\n",
    "\n",
    "\n",
    "-------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "\\begin{align}\n",
    "\\frac{d}{dx}g(x) &= \\frac{d}{dx}\\left[\\frac{1}{\\sqrt{2\\pi}\\sigma}\\exp\\left(-\\frac{x^2}{2\\sigma^2}\\right)\\right] = \\\\\n",
    "\n",
    "\\end{align}\n",
    "\n",
    "We can pull out constant factors:\n",
    "\n",
    "\\begin{equation}\n",
    "= \\frac{1}{\\sqrt{2} \\sqrt{\\pi} \\, {\\sigma}} \\cdot \\frac{\\mathrm{d}}{\\mathrm{d}x}\\left[\\mathrm{e}^{-\\frac{x^{2}}{2{\\sigma}^{2}}}\\right]\n",
    "\\end{equation}\n",
    "\n",
    "We apply the exponential function rule: $[e^{u(x)}]'=e^{u(x)}*u'(x)$\n",
    "\n",
    "\\begin{equation}\n",
    "= \\frac{\\mathrm{e}^{-\\frac{x^{2}}{2{\\sigma}^{2}}} \\cdot \\frac{\\mathrm{d}}{\\mathrm{d}x}\\left[-\\frac{x^{2}}{2{\\sigma}^{2}}\\right]}{\\sqrt{2} \\sqrt{\\pi} \\, {\\sigma}}\n",
    "\\end{equation}\n",
    "\n",
    "Again we can pull out constants:\n",
    "\n",
    "\\begin{equation}\n",
    "= \\frac{\\mathrm{e}^{-\\frac{x^{2}}{2{\\sigma}^{2}}} \\left(-\\frac{1}{2{\\sigma}^{2}} \\cdot \\frac{\\mathrm{d}}{\\mathrm{d}x}\\left[x^{2}\\right]\\right)}{\\sqrt{2} \\sqrt{\\pi} \\, {\\sigma}}\n",
    "\\end{equation}\n",
    "\n",
    "Apply the power rule: $[x^n]'=nx^{n-1}$\n",
    "\n",
    "\\begin{equation}\n",
    "= -\\frac{\\mathrm{e}^{-\\frac{x^{2}}{2{\\sigma}^{2}}} \\cdot 2x}{2^{\\frac{3}{2}} \\sqrt{\\pi} \\, {\\sigma}^{3}}\n",
    "\\end{equation}\n",
    "\n",
    "Finally, we simplify the expression obtaining the first derivative of the Gaussian function:\n",
    "\n",
    "\\begin{equation}\n",
    "= -\\frac{x\\mathrm{e}^{-\\frac{x^{2}}{2{\\sigma}^{2}}}}{\\sqrt{2} \\sqrt{\\pi} \\, {\\sigma}^{3}}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:22:37.389018Z",
     "start_time": "2024-10-24T12:22:37.385029Z"
    }
   },
   "outputs": [],
   "source": [
    "def gaussdx(sigma: float) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    This function computes the first derivative of the 1D Gaussian operator.\n",
    "\n",
    "    Args:\n",
    "        sigma (float) : the standard deviation of the Gaussian filter\n",
    "\n",
    "    Returns:\n",
    "        Dx (np.ndarray): the first derivative of the 1D Gaussian operator\n",
    "        x (np.ndarray): the indexes of the 1D Gaussian operator\n",
    "    \"\"\"\n",
    "    #####################################################\n",
    "    ##              FIX THIS CODE (2 ERRORS)           ##\n",
    "    #####################################################\n",
    "    sigma = math.ceil(sigma)\n",
    "    filter_size = 3 * sigma + 1\n",
    "\n",
    "    # Generate the index x\n",
    "    zero_pos = 3 * filter_size  # the (zero_pos+1)th element is the 0 for the index\n",
    "\n",
    "    #First mistake\n",
    "    #Old row\n",
    "    #x = np.arange(filter_size) - zero_pos\n",
    "    #New row\n",
    "    x = np.arange(-filter_size, filter_size+1) # indexes from -3*sigma to 3*sigma\n",
    "\n",
    "    #Second mistake\n",
    "    #Old row\n",
    "    #Dx = x * np.exp(-(x**2) / (2.0 * sigma**2)) / (math.sqrt(2.0 * np.pi) * sigma)\n",
    "    #New row\n",
    "    # Compute the Gaussian curve with std-dev sigma at the indexes x\n",
    "    Dx = - x * np.exp(-(x**2) / (2.0 * sigma**2)) / (math.sqrt(2.0 * np.pi) * (sigma ** 3))\n",
    "\n",
    "    return Dx, x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "--------------------------------------------\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "To check that your implementation is correct, plot the result of the function with $\\sigma=3$ and compare it with the image below.\n",
    "\n",
    "![](./images/1gaussdx.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:22:37.496684Z",
     "start_time": "2024-10-24T12:22:37.389964Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot the first derivative of the 1D Gaussian operator\n",
    "sigma = 3\n",
    "Dx, x = gaussdx(sigma)\n",
    "plt.figure(1)\n",
    "plt.plot(x, Dx, \".-\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "_____________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:22:37.500333Z",
     "start_time": "2024-10-24T12:22:37.497450Z"
    }
   },
   "outputs": [],
   "source": [
    "def gauss_dxdy(img: np.ndarray, sigma: float) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    This function applies the first derivative of the 1D Gaussian operator to the image in the x and y directions.\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): the input image.\n",
    "        sigma (float): the standard deviation of the Gaussian filter.\n",
    "\n",
    "    Returns:\n",
    "        img_Dx (np.ndarray): the image after applying the first derivative of the 1D Gaussian operator in the x direction.\n",
    "        img_Dy (np.ndarray): the image after applying the first derivative of the 1D Gaussian operator in the y direction.\n",
    "    \"\"\"\n",
    "    #####################################################\n",
    "    ##                 FIX THIS CODE                   ##\n",
    "    #####################################################\n",
    "    Gx, _ = gauss(sigma, filter_size=6*sigma)\n",
    "    Dx, _ = gaussdx(sigma)\n",
    "\n",
    "    #First mistake\n",
    "    #Old row\n",
    "    #img_Dx = convolve1d(convolve1d(img, Dx), Gx)\n",
    "    #New row\n",
    "    img_Dx = convolve1d(convolve1d(img, Dx, axis=1), Gx, axis=0)\n",
    "\n",
    "    #Second mistake\n",
    "    #Old row\n",
    "    #img_Dy = convolve1d(convolve1d(img, Gx), Dx)\n",
    "    #New row\n",
    "    img_Dy = convolve1d(convolve1d(img, Dx, axis=0), Gx, axis=1)\n",
    "\n",
    "    return img_Dx, img_Dy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "--------------------------------------------\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "To check that your implementation is correct, plot the result of the function with $\\sigma=1$ and compare it with the images below.\n",
    "\n",
    "![](./images/check_gaussdxdy.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:22:37.693994Z",
     "start_time": "2024-10-24T12:22:37.501163Z"
    }
   },
   "outputs": [],
   "source": [
    "img_color = rgb2gray(np.array(Image.open(\"images/pinwheel.jpg\")))\n",
    "\n",
    "img_Dx, img_Dy = gauss_dxdy(img_color, 1)\n",
    "\n",
    "plot_pictures([img_Dx, img_Dy], [\"Dx\", \"Dy\"], 1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:22:37.699322Z",
     "start_time": "2024-10-24T12:22:37.694705Z"
    }
   },
   "outputs": [],
   "source": [
    "def hist_dxdy(img_gray, num_bins=5):\n",
    "    \"\"\"\n",
    "    This function computes the *joint* histogram of Gaussian partial derivatives of the image in x and y direction.\n",
    "    Set sigma to 3.0 and cap the range of derivative values is in the range [-6, 6].\n",
    "    The histogram should be normalized so that the sum of all values equals 1.\n",
    "\n",
    "    Args:\n",
    "        img_gray: the input image\n",
    "        num_bins: number of bins used to discretize each dimension, total number of bins in the histogram should be num_bins^2\n",
    "\n",
    "    Returns:\n",
    "        hists: the joint normalized histogram of Gaussian partial derivatives of the image in x and y direction\n",
    "    \"\"\"\n",
    "\n",
    "    assert len(img_gray.shape) == 2, \"image dimension mismatch\"\n",
    "    assert img_gray.dtype == \"float\", \"incorrect image type\"\n",
    "    \n",
    "    #####################################################\n",
    "    ##                 FIX THIS CODE                   ##\n",
    "    #####################################################\n",
    "\n",
    "    # Compute the first derivatives of img_gray\n",
    "    sigma = 3.0\n",
    "    img_dx, img_dy = gauss_dxdy(img_gray, sigma)\n",
    "\n",
    "    # Set the min_der and max_der to -6 and 6, which defines the ranges for quantization\n",
    "    min_der, max_der = (-6, 6)\n",
    "\n",
    "    # Flatten the 2D derivative images to 1D arrays\n",
    "    img_dx = img_dx.reshape(-1)\n",
    "    img_dy = img_dy.reshape(-1)\n",
    "\n",
    "    # Clip the min and max values to min_der and max_der respectively\n",
    "    # and shift minumum values to 0\n",
    "    img_dx = np.clip(img_dx, min_der, max_der) + max_der\n",
    "\n",
    "    # mistake 1: shifting was not applied to dy\n",
    "    # the range should be [0, 12] instead of [-6, 6]\n",
    "    img_dy = np.clip(img_dy, min_der, max_der) + max_der\n",
    "\n",
    "    hists = np.zeros((num_bins, num_bins), dtype=int)\n",
    "    bin_range = (max_der - min_der) / num_bins\n",
    "\n",
    "    # quantize image derivative valuer into bins\n",
    "    bin_dx = np.floor(img_dx / bin_range).astype(int)\n",
    "    bin_dy = np.floor(img_dy / bin_range).astype(int)\n",
    "    bin_dx = np.clip(bin_dx, 0, num_bins - 1)\n",
    "    bin_dy = np.clip(bin_dy, 0, num_bins - 1)\n",
    "\n",
    "    for i in range(bin_dx.size):\n",
    "        hists[bin_dx[i], bin_dy[i]] += 1\n",
    "\n",
    "    # mistake 2: hists was not normalized in the range [0,1]\n",
    "    hists = hists.flatten().astype(np.float64)\n",
    "    hists /= hists.sum()\n",
    "    return hists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "--------------------------------------------\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "To check that your implementation is correct, compare it with the image below.\n",
    "\n",
    "![](./images/check_hist_dxdy.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:22:38.239628Z",
     "start_time": "2024-10-24T12:22:37.700285Z"
    }
   },
   "outputs": [],
   "source": [
    "img_color = np.array(Image.open(\"images/pinwheel.jpg\"))\n",
    "img_gray = rgb2gray(img_color.astype(\"double\"))\n",
    "\n",
    "plt.figure(5)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(img_color)\n",
    "\n",
    "num_bins_dxdy = 10\n",
    "plt.subplot(1, 2, 2)\n",
    "hist_dxdy_ = hist_dxdy(img_gray, num_bins_dxdy)\n",
    "plt.bar(np.array(range(1, hist_dxdy_.size + 1)), hist_dxdy_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### **Theoretical questions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now that you have implemented two color histograms - 3D joint and GB - and the dx/dy histogram, answer to the following questions:\n",
    "\n",
    "1. What does the dx/dy histogram represent in terms of image features?\n",
    "2. In your opinion, which of the two types of histograms (color and dx/dy) is more robust to changes in illumination? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "-------------------------------------------------------\n",
    "\n",
    "\n",
    "1.\tThe dx/dy histogram represents the distribution of the prime derivatives of the image intensity values along the x and y directions. It captures gradient information that is essential for detecting edges and other local features. The bins of the histogram correspond to the frequency of different orientations and magnitudes of the gradient in the image, providing insight into the structure and texture of the image.\n",
    "\n",
    "2.\tThe dx/dy histogram is stronger to changes in illumination than the color histograms. This is because the dx/dy histogram focuses on the gradient information of the image, which is less sensitive to global illumination changes. Gradient-based features vary much less to changes in illumination conditions because they capture intensity changes and local edges that are less affected by overall brightness or color changes. In contrast, color histograms are more sensitive to changes in illumination because they depend directly on pixel values and color distributions in the image, which can be significantly altered by changes in illumination, making a pixel brighter or darker\n",
    "\n",
    "-------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### **3.3: Histogram Metrics** *(2 points)*\n",
    "\n",
    "Now that you have implemented and used different types of histograms, let's consider distance functions.\n",
    "1. Write the definition of intersection distance function, $L_2$, and $\\chi^2$ distance functions.\n",
    "2. Implement each one of them.\n",
    "3. Write down some considerations on each one of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Complete the definition of each metric.\n",
    "\n",
    "* Intersection function **for unnormalized histograms**:\n",
    "\n",
    "The intersection distance is a measure that computes the overlap between two histograms\n",
    "\\begin{equation}\n",
    "\\bigcap(Q,V)= \\frac{1}{2} \\left( \\frac{\\sum_{i=1}^{n}min(q_i,v_i)}{\\sum_{i=1}^{n}q_i} + \\frac{\\sum_{i=1}^{n}min(q_i,v_i)}{\\sum_{i=1}^{n}v_i} \\right)\n",
    "\\end{equation}\n",
    "\n",
    "The $L_2$ distance, also known as the Euclidean distance, is a standard measure of the distance between two points in a multidimensional space. For histograms\n",
    "\n",
    "* $L_2$ function:\n",
    "\\begin{equation}\n",
    "d(Q,V)= \\sqrt{\\sum_{i=1}^{n}(q_i-v_i)^2}\n",
    "\\end{equation}\n",
    "\n",
    "* $\\chi^2$ function:\n",
    "\\begin{equation}\n",
    "\\chi^2(Q,V)= \\sum_{i=1}^{n} \\frac{(q_i-v_i)^2}{q_i+v_i}\n",
    "\\end{equation}\n",
    "\n",
    "Unusual metric:\n",
    "\n",
    "* Negative Cross-Entropy function:\n",
    "\\begin{equation}\n",
    "H(P, Q) = - \\sum_{i=1}^{n} P_i \\log(q_i)\n",
    "\\end{equation}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:22:38.243777Z",
     "start_time": "2024-10-24T12:22:38.240421Z"
    }
   },
   "outputs": [],
   "source": [
    "def hist_intersect(h1: np.ndarray, h2: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Compute the intersection between histograms x and y.\n",
    "    Check that the distance range is [0,1].\n",
    "\n",
    "    Args:\n",
    "        h1 (np.ndarray): Input histogram.\n",
    "        h2 (np.ndarray): Input histogram.\n",
    "\n",
    "    Returns:\n",
    "        x (float): Intersection distance between histograms x and y.\n",
    "    \"\"\"\n",
    "\n",
    "    #####################################################\n",
    "    ##                 YOUR CODE HERE                  ##\n",
    "    #####################################################\n",
    "    intersection = np.minimum(h1, h2)\n",
    "    sum_intersection = np.sum(intersection)\n",
    "    sum_h1 = np.sum(h1)\n",
    "    sum_h2 = np.sum(h2)\n",
    "    return 0.5 * (sum_intersection / sum_h1 + sum_intersection / sum_h2)\n",
    "\n",
    "\n",
    "def hist_l2(h1: np.ndarray, h2: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Compute the L2 between x and y histograms.\n",
    "    Check that the distance range in [0,sqrt(2)].\n",
    "\n",
    "    Args:\n",
    "        h1 (np.ndarray): Input histogram.\n",
    "        h2 (np.ndarray): Input histogram.\n",
    "\n",
    "    Returns:\n",
    "        x (float): L2 distance between x and y histograms.\n",
    "    \"\"\"\n",
    "\n",
    "    #####################################################\n",
    "    ##                 YOUR CODE HERE                  ##\n",
    "    #####################################################\n",
    "    return np.sqrt(np.sum((h1 - h2) ** 2))\n",
    "\n",
    "\n",
    "def hist_chi2(h1: np.ndarray, h2: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Compute chi2 between x and y.\n",
    "    Check that the distance range in [0,Inf].\n",
    "\n",
    "    Args:\n",
    "        h1 (np.ndarray): Input histogram.\n",
    "        h2 (np.ndarray): Input histogram.\n",
    "\n",
    "    Returns:\n",
    "        x (float): Chi2 distance between x and y.\n",
    "    \"\"\"\n",
    "    # TODO capire perchè esce diverso\n",
    "    epsilon = 1e-10  # Small constant to avoid division by zero\n",
    "    return np.sum(((h1 - h2) ** 2) / (h1 + h2 + epsilon))\n",
    "\n",
    "\n",
    "def hist_ce(h1: np.ndarray, h2: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Compute the cross-entropy between two histograms.\n",
    "\n",
    "    Args:\n",
    "        h1 (np.ndarray): First input histogram.\n",
    "        h2 (np.ndarray): Second input histogram.\n",
    "\n",
    "    Returns:\n",
    "        float: Cross-entropy between h1 and h2.\n",
    "    \"\"\"\n",
    "    epsilon = 1e-10  # Small constant to avoid log(0)\n",
    "    return -np.sum(h1 * np.log(h2 + epsilon))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "--------------------------------------------\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:22:38.600635Z",
     "start_time": "2024-10-24T12:22:38.244619Z"
    }
   },
   "outputs": [],
   "source": [
    "img1 = np.array(Image.open(\"model/obj100__0.png\"))\n",
    "img2 = np.array(Image.open(\"model/obj63__0.png\"))\n",
    "\n",
    "num_bins_color = 5\n",
    "hist1 = gb_hist(img1.astype(\"double\"), num_bins_color)\n",
    "hist2 = gb_hist(img2.astype(\"double\"), num_bins_color)\n",
    "\n",
    "# plot images and histograms\n",
    "plt.figure(6, figsize=(16, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(img1)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(img2)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(7, figsize=(16, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(np.array(range(1, hist1.size + 1)), hist1)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(np.array(range(1, hist2.size + 1)), hist2)\n",
    "plt.show()\n",
    "\n",
    "metrics = np.array(\n",
    "    [hist_intersect(hist1, hist2), hist_l2(hist1, hist2), hist_chi2(hist1, hist2), hist_ce(hist1, hist2)]\n",
    ")\n",
    "\n",
    "# write distances to file\n",
    "np.savetxt(\"assets/metrics.npy\", metrics)\n",
    "\n",
    "# read metrics from file\n",
    "metrics = np.loadtxt(\"assets/metrics.npy\")\n",
    "\n",
    "# print distances and compare them with the solution\n",
    "print(f\"Intersection:\\n\\t{metrics[0]}\\t{hist_intersect(hist1, hist2)}\")\n",
    "print(f\"L2:\\n\\t{metrics[1]}\\t{hist_l2(hist1, hist2)}\")\n",
    "print(f\"Chi2:\\n\\t{metrics[2]}\\t{hist_chi2(hist1, hist2)}\")\n",
    "print(f\"CE:\\n\\t{metrics[3]}\\t{hist_ce(hist1, hist2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### **3.4: Image Retrieval** *(2 points)*\n",
    "\n",
    "Now that you have implemented and used different types of histograms, it's time to test how suitable they are for retrieving images in a query-by-example scenario.\n",
    "\n",
    "Implement a function called `find_best_match` that returns the closest model images for each query image.\n",
    "The function takes input string parameters, identifying the distance function, histogram function, and the number of histogram bins.\n",
    "\n",
    "*Note: See comments at the beginning of the `find_best_match` function for more details.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "--------------------------------------------\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:22:38.605896Z",
     "start_time": "2024-10-24T12:22:38.601515Z"
    }
   },
   "outputs": [],
   "source": [
    "def is_grayvalue_hist(hist_name: str) -> bool:\n",
    "    \"\"\"\n",
    "    Handle function to discriminate when your input\n",
    "    function is in gray_scale or colors.\n",
    "\n",
    "    Args:\n",
    "        hist_name (str): histogram name.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the histogram is in gray_scale, False otherwise.\n",
    "    \"\"\"\n",
    "    if hist_name == \"grayvalue\" or hist_name == \"dxdy\":\n",
    "        return True\n",
    "    elif hist_name == \"rgb\" or hist_name == \"gb\":\n",
    "        return False\n",
    "    else:\n",
    "        assert False, \"unknown histogram type\"\n",
    "\n",
    "\n",
    "def get_hist_by_name(img: np.ndarray, num_bins_gray: int, hist_name: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Handle function to get the correct historgam function\n",
    "    by his name.\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): input image.\n",
    "        num_bins_gray (int): number of bins for the gray_scale histogram.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: histogram.\n",
    "    \"\"\"\n",
    "    # if hist_name == \"rgb\":\n",
    "    #     return rgb_hist(img, num_bins_gray)\n",
    "    if hist_name == \"gb\":\n",
    "        return gb_hist(img, num_bins_gray)\n",
    "    elif hist_name == \"dxdy\":\n",
    "        return hist_dxdy(img, num_bins_gray)\n",
    "    else:\n",
    "        assert False, \"unknown hist type: %s\" % hist_name\n",
    "\n",
    "\n",
    "def get_dist_by_name(x: np.ndarray, y: np.ndarray, dist_name: str) -> float:\n",
    "    \"\"\"\n",
    "    Handle function to get the correct distance function\n",
    "    by his name.\n",
    "\n",
    "    Args:\n",
    "        x (np.ndarray): input histogram.\n",
    "        y (np.ndarray): input histogram.\n",
    "\n",
    "    Returns:\n",
    "        float: distance.\n",
    "    \"\"\"\n",
    "    if dist_name == \"chi2\":\n",
    "        return hist_chi2(x, y)\n",
    "    elif dist_name == \"intersect\":\n",
    "        return 1 - hist_intersect(x, y)\n",
    "    elif dist_name == \"l2\":\n",
    "        return hist_l2(x, y)\n",
    "    elif dist_name == \"ce\":\n",
    "        return hist_ce(x, y)\n",
    "    elif dist_name == \"all\":\n",
    "        pass\n",
    "    else:\n",
    "        assert False, \"unknown distance: %s\" % dist_name\n",
    "\n",
    "\n",
    "def read_files(\n",
    "    model_path: str = \"assets/model.txt\", query_path: str = \"assets/query.txt\"\n",
    ") -> Tuple[List[str], List[str]]:\n",
    "    \"\"\"\n",
    "    Handle function to read query and model files.\n",
    "\n",
    "    Args:\n",
    "        model_path (str): path to the model file.\n",
    "        query_path (str): path to the query file.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List[str], List[str]]: query images and model images.\n",
    "    \"\"\"\n",
    "    with open(model_path) as fp:\n",
    "        model_images = fp.readlines()\n",
    "    model_images = [x.strip() for x in model_images]\n",
    "\n",
    "    with open(query_path) as fp:\n",
    "        query_images = fp.readlines()\n",
    "    query_images = [x.strip() for x in query_images]\n",
    "\n",
    "    return query_images, model_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:22:38.612876Z",
     "start_time": "2024-10-24T12:22:38.606835Z"
    }
   },
   "outputs": [],
   "source": [
    "# note: use functions 'get_dist_by_name', 'get_hist_by_name' and 'is_grayvalue_hist' to obtain\n",
    "#       handles to distance and histogram functions, and to find out whether histogram function\n",
    "#       expects grayvalue or color image\n",
    "\n",
    "\n",
    "def compute_histograms(\n",
    "    image_list: List[np.ndarray], hist_type: str, hist_isgray: bool, num_bins: int\n",
    ") -> List[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Compute the histogram for each image in image_list.\n",
    "\n",
    "    Args:\n",
    "        image_list (List[np.ndarray]): list of images.\n",
    "        hist_type (str): histogram type.\n",
    "        hist_isgray (bool): True if the histogram is in gray_scale, False otherwise.\n",
    "        num_bins (int): number of bins for the gray_scale histogram.\n",
    "\n",
    "    Returns:\n",
    "        image_hist (List[np.ndarray]): list of histograms.\n",
    "    \"\"\"\n",
    "    #####################################################\n",
    "    ##                 YOUR CODE HERE                  ##\n",
    "    #####################################################\n",
    "    image_hist = []\n",
    "\n",
    "    for img_path in image_list:\n",
    "        # Open the image using Pillow\n",
    "        img = Image.open(img_path)\n",
    "\n",
    "        # Convert to grayscale if needed\n",
    "        if hist_isgray:\n",
    "            img = img.convert('L')  # 'L' mode is for grayscale\n",
    "\n",
    "        # Convert image to a NumPy array\n",
    "        img_array = np.array(img)\n",
    "\n",
    "        # Compute the appropriate histogram\n",
    "        hist = get_hist_by_name(img_array, num_bins, hist_type)\n",
    "        image_hist.append(hist)\n",
    "\n",
    "    return image_hist\n",
    "\n",
    "def find_best_match(\n",
    "    model_images: List[str],\n",
    "    query_images: List[str],\n",
    "    dist_type: str,\n",
    "    hist_type: str,\n",
    "    num_bins: int,\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Function to find the best match for each image in the\n",
    "    query folder.\n",
    "\n",
    "    Args:\n",
    "        model_images (List[str]): list of strings with the path of model images.\n",
    "        query_images (List[str]): list of strings with the path of query images.\n",
    "        dist_type (str): a string to represent the name of the distance you want to use. Should be one among \"l2\", \"intersect\", \"chi2\".\n",
    "        hist_type (str): a string to represent the name of the histogram you want to use. Should be one among \"grayvalue\", \"rgb\", \"rg\", \"dxdy\".\n",
    "        num_bins (int): number of bins for the gray_scale histogram.\n",
    "\n",
    "    Returns:\n",
    "        best_match (np.ndarray): list containing in each position the index of the retrieved best matching image.\n",
    "        D (np.ndarray): Matrix with |model_images| rows and |query_images| columns containing the scores of each matching.\n",
    "    #\"\"\"\n",
    "    #####################################################\n",
    "    ##                 YOUR CODE HERE                  ##\n",
    "    #####################################################\n",
    "# Determine if histogram is grayscale or color\n",
    "    hist_isgray = is_grayvalue_hist(hist_type)\n",
    "\n",
    "    # Compute histograms for both model and query images\n",
    "    model_hists = compute_histograms(model_images, hist_type, hist_isgray, num_bins)\n",
    "    query_hists = compute_histograms(query_images, hist_type, hist_isgray, num_bins)\n",
    "\n",
    "    # Initialize distance matrix\n",
    "    D = np.zeros((len(model_images), len(query_images)))\n",
    "\n",
    "    # Find the best match for each query image\n",
    "    best_match = np.zeros(len(query_images), dtype=int)\n",
    "\n",
    "    for q_idx, query_hist in enumerate(query_hists):\n",
    "        best_dist = float('inf')\n",
    "        best_model_idx = -1\n",
    "\n",
    "        for m_idx, model_hist in enumerate(model_hists):\n",
    "            dist = get_dist_by_name(query_hist, model_hist, dist_type)\n",
    "            D[m_idx, q_idx] = dist\n",
    "\n",
    "            if dist < best_dist:\n",
    "                best_dist = dist\n",
    "                best_model_idx = m_idx\n",
    "\n",
    "        best_match[q_idx] = best_model_idx\n",
    "\n",
    "    return best_match, D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EInVn-br5h1u"
   },
   "source": [
    "--------------------------------------------\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:52:52.977517Z",
     "start_time": "2024-10-24T12:52:48.198341Z"
    },
    "id": "lwhtN9h5zFsw"
   },
   "outputs": [],
   "source": [
    "# model_images - list of file names of model images\n",
    "# query_images - list of file names of query images\n",
    "\n",
    "query_images, model_images = read_files()\n",
    "\n",
    "dist_type = \"intersect\"\n",
    "hist_type = \"gb\"\n",
    "num_bins = 10\n",
    "\n",
    "[best_match, D] = find_best_match(\n",
    "    model_images, query_images, dist_type, hist_type, num_bins\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"Indexes of correct retrieved images is:\\n \",\n",
    "    *np.where(best_match == np.arange(len(query_images)))\n",
    ")\n",
    "print(\n",
    "    \"The Recognition rate is\",\n",
    "    sum(best_match == np.arange(len(query_images))) / len(query_images),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82QRWPM95lpW"
   },
   "source": [
    "--------------------------------------------\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jQD3_DRtsjlq"
   },
   "source": [
    "### **Report** *(2 points)*\n",
    "\n",
    "Experiment with different functions and numbers of histogram bins, and find a combination that works best. **Submit the summary of your experiments in a report as part of your solution.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mt8zvGFbsjlu"
   },
   "source": [
    "----------------------------\n",
    "\n",
    "**Fill the table below - CAPIRE SE I CONTENUTI SONO CORRETTI** \n",
    "\n",
    "----------------------------\n",
    "\n",
    "\n",
    "|  | Number of Bins | Metric(Distance Metric) | Accuracy |\n",
    "|---|---|---|---|\n",
    "| 1 |10|intersect|0.6966292134831461|\n",
    "| 2 |15|intersect|0.7865168539325843|\n",
    "| 3 |24|intersect|0.8314606741573034|\n",
    "| 4 |34|intersect|0.8426966292134831|\n",
    "| 5 |13|l2|0.6067415730337079|\n",
    "| 6 |8|l2|0.6179775280898876|\n",
    "| 7 |12|l2|0.6292134831460674|\n",
    "| 5 |13|chi2|0.8539325842696629|\n",
    "| 6 |14|chi2|0.8651685393258427|\n",
    "| 7 |12|chi2|0.8651685393258427|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "89MN4RssD7yZ"
   },
   "source": [
    "## **Question 4: Performance Evaluation** *(5 Points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UdM1CGjYD7yZ"
   },
   "source": [
    "In this question, your goal is to implement different types of metrics to evaluate the performance of a binary classificator.\n",
    "\n",
    "For the purpose of this exercise you don't need to know the inner workings of the ML model, therefore imagine to have a black box model that estimates the probability of an event occurring, such as the sky being clear or not, based on a given dataset of independent variables. Since the outcome is a probability, the dependent variable is bounded between 0 and 1.\n",
    "\n",
    "In order to compute a performance score (e.g., accuracy), you need to compare your predictions with the true values. So you need to convert the predicted probabilities into 0s and 1s by means of a threshold.\n",
    "\n",
    "What you have to do is the following:\n",
    "- **compute the performance** of the model with all the possible tresholds in the interval \\[0.0, 1.0\\] with increments of 0.5\n",
    "- **analyze** how the metrics vary at different thresholds and **write a report** on your analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VuqZnNITD7yZ"
   },
   "source": [
    "### **4.1: Performance Evaluation** *(2 points)*\n",
    "\n",
    "Write the code to compute the metrics for performance evaluation, then run the provided code cell to check if your results are correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8HnFVYqqD7yZ"
   },
   "source": [
    "--------------------------------------------\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:22:41.844331Z",
     "start_time": "2024-10-24T12:22:41.830316Z"
    },
    "id": "ii6ReMEjD7ya"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./assets/ionosphere.data\", header=None)\n",
    "X = data[data.columns[:34]]\n",
    "y = data[data.columns[-1]]\n",
    "y = np.array([0 if value == \"b\" else 1 for value in y])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "clf = LogisticRegression(random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:22:41.850431Z",
     "start_time": "2024-10-24T12:22:41.845099Z"
    },
    "id": "OmD1TO48D7ya"
   },
   "outputs": [],
   "source": [
    "def my_accuracy_score(y_true: list, y_pred: list) -> float:\n",
    "    \"\"\"\n",
    "    Compute the accuracy score.\n",
    "\n",
    "    Args:\n",
    "        y_true (list): list of true labels.\n",
    "        y_pred (list): list of predicted labels.\n",
    "\n",
    "    Returns:\n",
    "        float: accuracy score.\n",
    "    \"\"\"\n",
    "    correct_predictions = sum(t == p for t, p in zip(y_true, y_pred))\n",
    "    accuracy = correct_predictions / len(y_true)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def my_precision_score(y_true: list, y_pred: list) -> float:\n",
    "    \"\"\"\n",
    "    Compute the precision score.\n",
    "\n",
    "    Args:\n",
    "        y_true (list): list of true labels.\n",
    "        y_pred (list): list of predicted labels.\n",
    "\n",
    "    Returns:\n",
    "        float: precision score.\n",
    "    \"\"\"\n",
    "    true_positives = sum((t == 1 and p == 1) for t, p in zip(y_true, y_pred))\n",
    "    predicted_positives = sum(p == 1 for p in y_pred)\n",
    "    precision = true_positives / predicted_positives if predicted_positives else 0\n",
    "    return precision\n",
    "\n",
    "\n",
    "def my_recall_score(y_true: list, y_pred: list) -> float:\n",
    "    \"\"\"\n",
    "    Compute the recall score.\n",
    "\n",
    "    Args:\n",
    "        y_true (list): list of true labels.\n",
    "        y_pred (list): list of predicted labels.\n",
    "\n",
    "    Returns:\n",
    "        float: recall score.\n",
    "    \"\"\"\n",
    "    true_positives = sum((t == 1 and p == 1) for t, p in zip(y_true, y_pred))\n",
    "    actual_positives = sum(t == 1 for t in y_true)\n",
    "    recall = true_positives / actual_positives if actual_positives else 0\n",
    "    return recall\n",
    "\n",
    "\n",
    "def my_f1_score(y_true: list, y_pred: list) -> float:\n",
    "    \"\"\"\n",
    "    Compute the f1 score.\n",
    "\n",
    "    Args:\n",
    "        y_true (list): list of true labels.\n",
    "        y_pred (list): list of predicted labels.\n",
    "\n",
    "    Returns:\n",
    "        float: f1 score.\n",
    "    \"\"\"\n",
    "    precision = my_precision_score(y_true, y_pred)\n",
    "    recall = my_recall_score(y_true, y_pred)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) else 0\n",
    "    return f1\n",
    "\n",
    "\n",
    "def my_confusion_matrix(y_true: list, y_pred: list) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute the confusion matrix.\n",
    "\n",
    "    Args:\n",
    "        y_true (list): list of true labels.\n",
    "        y_pred (list): list of predicted labels.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: confusion matrix.\n",
    "    \"\"\"\n",
    "    tp = sum((t == 1 and p == 1) for t, p in zip(y_true, y_pred))\n",
    "    tn = sum((t == 0 and p == 0) for t, p in zip(y_true, y_pred))\n",
    "    fp = sum((t == 0 and p == 1) for t, p in zip(y_true, y_pred))\n",
    "    fn = sum((t == 1 and p == 0) for t, p in zip(y_true, y_pred))\n",
    "    matrix = [[tn, fp], [fn, tp]]\n",
    "    return np.array(matrix, dtype=np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iKAToEBHD7ya"
   },
   "source": [
    "--------------------------------------------\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:22:41.862884Z",
     "start_time": "2024-10-24T12:22:41.851342Z"
    },
    "id": "gT89287JD7ya"
   },
   "outputs": [],
   "source": [
    "# CHECK IF YOUR METRICS ARE CORRECT BY RUNNING THIS CODE CELL\n",
    "\n",
    "def compare_metric(my_metric_fun, metric_fun, y_test, preds):\n",
    "    try:\n",
    "        if my_metric_fun.__name__ != \"my_confusion_matrix\":\n",
    "            assert round(my_metric_fun(y_test, preds), 4) == round(\n",
    "                metric_fun(y_test, preds), 4\n",
    "            )\n",
    "        else:\n",
    "            assert np.array_equal(\n",
    "                my_metric_fun(y_test, preds), metric_fun(y_test, preds)\n",
    "            )\n",
    "        print(f\"{my_metric_fun.__name__} is correct\")\n",
    "    except:\n",
    "        print(f\"{my_metric_fun.__name__} is wrong\")\n",
    "\n",
    "\n",
    "preds = np.array([0 if p < 0.5 else 1 for p in y_pred])\n",
    "compare_metric(my_accuracy_score, accuracy_score, y_test, preds)\n",
    "compare_metric(my_precision_score, precision_score, y_test, preds)\n",
    "compare_metric(my_recall_score, recall_score, y_test, preds)\n",
    "compare_metric(my_f1_score, f1_score, y_test, preds)\n",
    "compare_metric(my_confusion_matrix, confusion_matrix, y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ZMdeYnJD7yb"
   },
   "source": [
    "### **4.2: Closest Neighbours** *(2 points)*\n",
    "\n",
    "Implement a function `show_neighbors`, which inputs a list of model images and a list of query images.\n",
    "For each query image, the function has to output a visualization of 5 model images which are most similar to the query image according to the specified distance metric.\n",
    "\n",
    "*HINT: use the function `find_best_match`.*\n",
    "\n",
    "![](images/neighbors.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:22:41.867780Z",
     "start_time": "2024-10-24T12:22:41.863853Z"
    },
    "id": "iYcuVCdDD7yb"
   },
   "outputs": [],
   "source": [
    "def show_neighbors(\n",
    "    model_images: List[str],\n",
    "    query_images: List[str],\n",
    "    dist_type: str,\n",
    "    hist_type: str,\n",
    "    num_bins: int,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    For each image file from 'query_images' find and visualize the 5 nearest images from 'model_image'.\n",
    "\n",
    "    Note: use the previously implemented function 'find_best_match'\n",
    "\n",
    "    Args:\n",
    "        model_images (List[str]): list of strings with the path of model images.\n",
    "        query_images (List[str]): list of strings with the path of query images.\n",
    "        dist_type (str): a string to represent the name of the distance you want to use. Should be one among \"l2\", \"intersect\", \"chi2\".\n",
    "        hist_type (str): a string to represent the name of the histogram you want to use. Should be one among \"grayvalue\", \"rgb\", \"rg\", \"dxdy\".\n",
    "        num_bins (int): number of bins for the gray_scale histogram.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    _, distance_matrix = find_best_match(model_images, query_images, dist_type, hist_type, num_bins)\n",
    "    \n",
    "    for q_idx, query_img in enumerate(query_images):\n",
    "        # get the 5 minimum distances for the query image and get the index\n",
    "        best_matches = np.argsort(distance_matrix[:, q_idx])[:5]\n",
    "    \n",
    "        # Create a figure to display the query image and its 5 nearest neighbors\n",
    "        _, axes = plt.subplots(1, 6, figsize=(15, 3))\n",
    "        axes[0].imshow(Image.open(query_img))\n",
    "        axes[0].set_title(f\"Q{q_idx}\")\n",
    "        axes[0].axis(\"off\")\n",
    "\n",
    "        for i, match_idx in enumerate(best_matches):\n",
    "            model_img = Image.open(model_images[match_idx])\n",
    "            axes[i + 1].imshow(model_img)\n",
    "            axes[i + 1].set_title(f\"M{distance_matrix[match_idx, q_idx]:.2f}\")\n",
    "            axes[i + 1].axis(\"off\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:22:44.298048Z",
     "start_time": "2024-10-24T12:22:41.868715Z"
    },
    "id": "l9fu4dwXD7yb"
   },
   "outputs": [],
   "source": [
    "## visualize nearest neighbors\n",
    "query_images_vis = [query_images[i] for i in np.array([0, 4, 9])]\n",
    "show_neighbors(model_images, query_images_vis, 'intersect', hist_type, num_bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uBOUstxcD7yb"
   },
   "source": [
    "### **4.3: Retrieval Metrics (1 points)**\n",
    "In previous sections, we implemented classical metrics for classification tasks. However, since we've also created a find_best_match function, we can approach this as a retrieval task. This perspective allows us to find the top-k items that best match the input item.\n",
    "Given this retrieval approach, it's more appropriate to use a metric specifically designed for retrieval tasks.\n",
    "\n",
    "**Top-k Accuracy**\n",
    "\n",
    "This is a variation of the classical accuracy metric. Here's how it works:\n",
    "1. For each input item, we consider the top k results.\n",
    "2. We count the result as positive if at least one of these k results matches the correct label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:22:44.302239Z",
     "start_time": "2024-10-24T12:22:44.299122Z"
    },
    "id": "TnhUfZG6D7yb"
   },
   "outputs": [],
   "source": [
    "def topk_accuracy(y_true, y_pred, k:int) -> float:\n",
    "    \"\"\"\n",
    "    Compute the Top-K accuracy, i.e. check whether the\n",
    "    correct label is in the top-k results.\n",
    "\n",
    "    Args:\n",
    "        y_true (list): list of correct labels\n",
    "        y_pred (np.array): A matrix of size (num_samples, num_results)\n",
    "            where each cell contains the predicted score for each\n",
    "            element in the dataset\n",
    "        k (int): number of best matching items to consider\n",
    "\n",
    "    Returns:\n",
    "        topk_accuracy (float)\n",
    "    \"\"\"\n",
    "    #####################################################\n",
    "    ##                 YOUR CODE HERE                  ##\n",
    "    #####################################################\n",
    "\n",
    "    samples = len(y_true)\n",
    "    top_value = np.argsort(y_pred, axis=1)[:, :k]\n",
    "    correct = 0\n",
    "    for i in range(samples):\n",
    "        if y_true[i] in top_value[i]:\n",
    "            correct += 1\n",
    "            \n",
    "    return correct/samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fJtzIkgYD7yb"
   },
   "source": [
    "--------------------------------------------\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:22:44.308403Z",
     "start_time": "2024-10-24T12:22:44.303111Z"
    },
    "id": "zNFQvXOnD7yb"
   },
   "outputs": [],
   "source": [
    "if 'D' not in globals():\n",
    "    _,D = find_best_match(\n",
    "        model_images, query_images, dist_type, hist_type, num_bins\n",
    "    )\n",
    "y_true = np.arange(D.shape[0])\n",
    "\n",
    "topk_accuracy(y_true, D, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dgzw_DMvD7yb"
   },
   "source": [
    "Now that you understand how the Top-$k$ accuracy works:\n",
    "- Compute the top-k accuracy for each of the values of $k \\in \\{1,...,20\\}$.\n",
    "- Produce a plot, with the value $k$ on the x-axis and the topk-accuracy on the y-axis.\n",
    "- Which is the minimum value of $k$ for which the top-$k$ accuracy is at least 80%?\n",
    "- Which are the tradeoffs of incrementing $k$?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:22:44.460289Z",
     "start_time": "2024-10-24T12:22:44.309254Z"
    },
    "id": "jiZ5ks8vD7yc"
   },
   "outputs": [],
   "source": [
    "K = 20\n",
    "y_true; # These are the correct labels\n",
    "\n",
    "#####################################################\n",
    "##                 YOUR CODE HERE                  ##\n",
    "#####################################################\n",
    "x_values = [i for i in range(1, K+1)]\n",
    "res = [topk_accuracy(y_true, D, k) for k in x_values]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(x_values, res, marker='o', label='Top-K Accuracy')\n",
    "plt.xlabel('K (Top-K)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "plt.xticks(x_values)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3b_xtG08D7yc"
   },
   "source": [
    "-------------------------------------------------------\n",
    "\n",
    "\n",
    "**WRITE YOU ANSWER HERE**\n",
    "\n",
    "\n",
    "-------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DClNVUdvD7yc"
   },
   "source": [
    "The minimum value of k for which the top-k accuracy is at least 80% is 3.\n",
    "While increasing k improves accuracy, it can also make the metric less meaningful as it becomes easier to achieve a high score simply by including more predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E1_3VNedD7yc"
   },
   "source": [
    "### **4.4: Analysis and Report** *(1 points)*\n",
    "\n",
    "\n",
    "Consider again the metrics for the classifier in Question 4.1.\n",
    "Write the code to compute the metrics for all the possible tresholds in the interval (0.0, 1.0) with increments of 0.5 of `y_pred`.  \n",
    "Ideally, you should put everything into a pandas DataFrame and print it for a better visualization.  \n",
    "Then, write a report analyzing you your results. You have complete freedom on your analysis.\n",
    "\n",
    "Imagine also to be in a medical scenario where your model is predicting the presence or not of a desease and try to answer to the following questions:\n",
    "- What is the real life trade-off between high precision and high recall? What would you choose?\n",
    "- Why isn't the accuracy an appropriate measure in such scenario?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T12:22:44.463982Z",
     "start_time": "2024-10-24T12:22:44.461547Z"
    },
    "id": "hdyBtKyaD7yc"
   },
   "outputs": [],
   "source": [
    "# Inizializzation of the array of metrics and thresholds\n",
    "thresholds = np.arange(0.0, 1.1, 0.5)\n",
    "metrics = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    # Convert predicted probabilities to binary predictions\n",
    "    y_pred_bin = (y_pred >= threshold).astype(int)\n",
    "\n",
    "    # Calculate metrics with ous custom functions\n",
    "    precision = my_precision_score(y_true, y_pred_bin)\n",
    "    recall = my_recall_score(y_true, y_pred_bin)\n",
    "    f1 = my_f1_score(y_true, y_pred_bin)\n",
    "    accuracy = my_accuracy_score(y_true, y_pred_bin)\n",
    "    \n",
    "\n",
    "    metrics.append({\n",
    "        'Threshold': threshold,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1': f1\n",
    "    })\n",
    "\n",
    "# Convert the list of metrics to a pandas DataFrame\n",
    "df_metrics = pd.DataFrame(metrics)\n",
    "print(df_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------\n",
    "\n",
    "#### Report:\n",
    "\n",
    "Analysis of the table clearly shows how threshold variation affects the model's metrics. We start with accuracy, which remains constant at the very low value of 0.011 for all thresholds. This suggests that the model has a low ability to classify correctly, regardless of the threshold, probably due to an imbalance in the data or unreliable predictions.\n",
    "\n",
    "Looking at precision and recall, we see a different behaviour:\n",
    "- At low thresholds (0 and 0.5), recall is 1.0, indicating that the model correctly identifies all positive cases, but at the cost of low precision (0.011 at threshold 0 and 0.017 at threshold 0.5, respectively). This means that even if all positive cases are captured, there are many false positives, which reduces precision.\n",
    "- In contrast, when the threshold increases to 1.0, the precision becomes 0, indicating that the model no longer makes any positive predictions (classifies all cases as negative). This leads to a recall of 0.0, as no true positives are identified.\n",
    "\n",
    "The F1-score reflects this dynamic, balancing precision and recall: at threshold 0.5 it is little higher (0.033) than at threshold 0 or 1, but still remains very low, suggesting that the model does not balance precision and recall well at any threshold.\n",
    "\n",
    "#### In to Medical Scenario:\n",
    "\n",
    "In a medical context, the balance between high precision and high recall is crucial. High precision ensures that the positive cases identified are actually sick, reducing the number of false positives. This is important to avoid misdiagnosing healthy people as sick. On the other hand, a high recall ensures that the majority of sick people are detected, reducing the risk of false negatives, i.e. undiagnosed sick patients. The choice between accuracy and recall depends on the consequences of false positives and false negatives: in medicine, missing a sick person (false negative) can have very serious consequences, leading to a delay in treatment, hence priority is given to high recall\n",
    "\n",
    "Accuracy is not an appropriate measure in this context because it does not consider the imbalance between positive and negative cases. In medical scenarios, the number of healthy patients is usually much higher than the number of sick patients. A model that classified all patients as healthy might have high accuracy, but would not be useful for identifying sick patients. Accuracy and recall, on the other hand, provide a more detailed evaluation of the model, focusing on the balance between correctly identifying sick people and minimising misclassification errors.\n",
    "\n",
    "\n",
    "-------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
